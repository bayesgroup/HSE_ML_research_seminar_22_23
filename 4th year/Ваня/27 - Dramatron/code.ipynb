{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "pdl544otf95d5kzcy6ffp",
        "id": "fD1QUN5gJQSX"
      },
      "source": [
        "#Script Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "9se0v6v6nphrlf91o6hkq",
        "id": "QUyZuTWFJQSf"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "import helper\n",
        "data_dir = 'film_text.txt'\n",
        "text = helper.load_data(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "6js9gvylzjk8te6hb0rfk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfi39vmUJQSk",
        "outputId": "c58deb7b-89da-4f0e-9492-3ee1697058c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Stats\n",
            "Roughly the number of unique words: 286276\n",
            "Number of lines: 2081266\n",
            "Average number of words in each line: 2.922427022783248\n",
            "\n",
            "The lines 0 to 10:\n",
            "INT. HOUSE - CLOSED EYES                                                                                \n",
            "\n",
            "A young man's blue eyes slowly open.  A girl moans from the next room.\n",
            "\n",
            "\n",
            "EXT. STREET CORNER - A LARGE TIRE\n",
            "\n",
            "turns the corner and splashes through a puddle from an\n",
            "earlier rain. TUPAC SHAKUR blares from inside.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "view_line_range = (0, 10)\n",
        "import numpy as np\n",
        "\n",
        "print('Dataset Stats')\n",
        "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
        "\n",
        "lines = text.split('\\n')\n",
        "print('Number of lines: {}'.format(len(lines)))\n",
        "word_count_line = [len(line.split()) for line in lines]\n",
        "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
        "\n",
        "print()\n",
        "print('The lines {} to {}:'.format(*view_line_range))\n",
        "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "uhsynd5wzilbv1e5jc2of6",
        "id": "nGRBHPIuJQSm"
      },
      "source": [
        "---\n",
        "## Implement Pre-processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "xbm76t28mdmi63p5ykgfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYteGnG4JQSn",
        "outputId": "56ec667a-5d06-4f74-c4b2-ae98fe111fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "import problem_unittests as tests\n",
        "from collections import Counter\n",
        "\n",
        "def create_lookup_tables(text):\n",
        "    word_counts = Counter(text)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "    return (vocab_to_int, int_to_vocab)\n",
        "\n",
        "tests.test_create_lookup_tables(create_lookup_tables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "a2n4in0sm2r4b42i2nnnbr",
        "id": "Gx4LFxkZJQSp"
      },
      "source": [
        "### Tokenize Punctuation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "8qa02hwbbprojoxfglmja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkyVL6kxJQSq",
        "outputId": "30114345-2731-40de-df8b-9ff86000ad73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "def token_lookup():\n",
        "    token_dict = dict()\n",
        "    token_dict['.'] = \"||PERIOD||\"\n",
        "    token_dict[','] = \"||COMMA||\"\n",
        "    token_dict['\"'] = \"||QUOTATION_MARK||\"\n",
        "    token_dict[';'] = \"||SEMICOLON||\"\n",
        "    token_dict['!'] = \"||EXCLAMATION_MARK||\"\n",
        "    token_dict['?'] = \"||QUESTION_MARK||\"\n",
        "    token_dict['('] = \"||LEFT_PAREN||\"\n",
        "    token_dict[')'] = \"||RIGHT_PAREN||\"\n",
        "    token_dict['-'] = \"||DASH||\"\n",
        "    token_dict['\\n'] = \"||RETURN||\"\n",
        "    return token_dict\n",
        "\n",
        "tests.test_tokenize(token_lookup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "k69gto4n4rg77gb9izmpyt",
        "id": "jQhVsgn0JQSt"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "0druvrobgv42e43ati32ig",
        "id": "kTgX50M3JQSv"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "import helper\n",
        "import problem_unittests as tests\n",
        "\n",
        "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "zaoxe06b2fswrl5cllxxr",
        "id": "CuFyvoOEJQSv"
      },
      "source": [
        "## Build the Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "qduuxyvcetqhsrh10uo4f",
        "id": "6WxVXvjdJQSw"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "import torch\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('No GPU found. Please use a GPU to train your neural network.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "pmwdpvayoearcfvsl087e",
        "id": "EeBVHKr6JQSy"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def batch_data(words, sequence_length, batch_size):\n",
        "\n",
        "    n_batches = len(words)//batch_size\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    features, target = [], []\n",
        "    for idx in range(0, (len(words) - sequence_length)):\n",
        "        features.append(words[idx : idx + sequence_length])\n",
        "        target.append(words[idx + sequence_length])\n",
        "        \n",
        "    feature_tensor = torch.from_numpy(np.asarray(features))\n",
        "    target_tensor = torch.from_numpy(np.asarray(target))\n",
        "    \n",
        "    data = TensorDataset(feature_tensor, target_tensor)\n",
        "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "3j1ne3pefodrcbqmxi3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFl-RvmeJQSz",
        "outputId": "f8eca21d-477c-469a-8deb-033997ce4787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 5])\n",
            "tensor([[33, 34, 35, 36, 37],\n",
            "        [32, 33, 34, 35, 36],\n",
            "        [28, 29, 30, 31, 32],\n",
            "        [ 4,  5,  6,  7,  8],\n",
            "        [40, 41, 42, 43, 44],\n",
            "        [ 8,  9, 10, 11, 12],\n",
            "        [23, 24, 25, 26, 27],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [12, 13, 14, 15, 16],\n",
            "        [43, 44, 45, 46, 47]])\n",
            "\n",
            "torch.Size([10])\n",
            "tensor([38, 37, 33,  9, 45, 13, 28, 15, 17, 48])\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "test_text = range(50)\n",
        "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
        "\n",
        "data_iter = iter(t_loader)\n",
        "sample_x, sample_y = next(data_iter)\n",
        "\n",
        "print(sample_x.shape)\n",
        "print(sample_x)\n",
        "print()\n",
        "print(sample_y.shape)\n",
        "print(sample_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "9hpae7vtdcalrg6vvbjcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjg_Y1kaJQS1",
        "outputId": "710312c8-6dd2-4142-bd60-629bc97d0b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "        super(RNN, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    \n",
        "    \n",
        "    def forward(self, nn_input, hidden):  \n",
        "        batch_size = nn_input.size(0)\n",
        "\n",
        "        embeds = self.embedding(nn_input)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        output = out.view(batch_size, -1, self.output_size)\n",
        "        out = output[:, -1]\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "            \n",
        "        return hidden\n",
        "\n",
        "tests.test_rnn(RNN, train_on_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "3omagtrgj21lven4soo0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA9KP0zNJQS2",
        "outputId": "f7f59c8e-79d2-45b2-95bd-d454f6421442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests Passed\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
        "    clip=5\n",
        "    if train_on_gpu:\n",
        "        rnn.cuda()\n",
        "        inp, target = inp.cuda(), target.cuda()\n",
        "    h = tuple([each.data for each in hidden])\n",
        "    rnn.zero_grad()\n",
        "    output, h = rnn(inp, h)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    return loss.item(), h\n",
        "\n",
        "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "fppni5b3rffpydwa0vqde",
        "id": "JFEUXsFBJQS2"
      },
      "source": [
        "## Neural Network Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "3ftfqzt76yqjpas8l24mb8",
        "id": "ZVErl3gUJQS4"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "Set and train the neural network with the following parameters:\n",
        "- Set `sequence_length` to the length of a sequence.\n",
        "- Set `batch_size` to the batch size.\n",
        "- Set `num_epochs` to the number of epochs to train for.\n",
        "- Set `learning_rate` to the learning rate for an Adam optimizer.\n",
        "- Set `vocab_size` to the number of uniqe tokens in our vocabulary.\n",
        "- Set `output_size` to the desired size of the output.\n",
        "- Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.\n",
        "- Set `hidden_dim` to the hidden dimension of your RNN.\n",
        "- Set `n_layers` to the number of layers/cells in your RNN.\n",
        "- Set `show_every_n_batches` to the number of batches at which the neural network should print progress.\n",
        "\n",
        "If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "mbohdbxuzl9m89b2jiy89i",
        "id": "qfgEmwpyJQS3"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    rnn.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "\n",
        "        hidden = rnn.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    return rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "9qqyycy6zabjnt8ox3mkmr",
        "id": "w76W81I6JQS4"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "sequence_length = 12\n",
        "batch_size = 128\n",
        "train_loader = batch_data(int_text, sequence_length, batch_size)\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001\n",
        "vocab_size = len(vocab_to_int)\n",
        "output_size = vocab_size\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "show_every_n_batches = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "4x24y36zm0cof2ez93ymy",
        "id": "lkdXkh4hJQS4"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "15r65190mgkdqwrdl4rjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yVceg69JQS5",
        "outputId": "8415d323-f868-4785-ea07-66f18fbb4e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 2 epoch(s)...\n",
            "Epoch:    1/2     Loss: 5.73177996635437\n",
            "\n",
            "Epoch:    1/2     Loss: 5.160752718687058\n",
            "\n",
            "Epoch:    1/2     Loss: 5.009104348421097\n",
            "\n",
            "Epoch:    1/2     Loss: 4.91757381439209\n",
            "\n",
            "Epoch:    1/2     Loss: 4.828801354408264\n",
            "\n",
            "Epoch:    1/2     Loss: 4.781493105173111\n",
            "\n",
            "Epoch:    1/2     Loss: 4.7553358438014985\n",
            "\n",
            "Epoch:    1/2     Loss: 4.722130950927735\n",
            "\n",
            "Epoch:    1/2     Loss: 4.661684648275376\n",
            "\n",
            "Epoch:    1/2     Loss: 4.653225932121277\n",
            "\n",
            "Epoch:    1/2     Loss: 4.646141780614853\n",
            "\n",
            "Epoch:    1/2     Loss: 4.620412744760514\n",
            "\n",
            "Epoch:    1/2     Loss: 4.591969912052154\n",
            "\n",
            "Epoch:    1/2     Loss: 4.5877769069671634\n",
            "\n",
            "Epoch:    1/2     Loss: 4.574117929935455\n",
            "\n",
            "Epoch:    1/2     Loss: 4.537620231628418\n",
            "\n",
            "Epoch:    1/2     Loss: 4.548403714418411\n",
            "\n",
            "Epoch:    1/2     Loss: 4.538714349508285\n",
            "\n",
            "Epoch:    1/2     Loss: 4.5360903034210205\n",
            "\n",
            "Epoch:    1/2     Loss: 4.524991992950439\n",
            "\n",
            "Epoch:    1/2     Loss: 4.517101494550705\n",
            "\n",
            "Epoch:    1/2     Loss: 4.508823357343673\n",
            "\n",
            "Epoch:    1/2     Loss: 4.520146298646927\n",
            "\n",
            "Epoch:    1/2     Loss: 4.489712931156158\n",
            "\n",
            "Epoch:    1/2     Loss: 4.506817892789841\n",
            "\n",
            "Epoch:    1/2     Loss: 4.487675382614135\n",
            "\n",
            "Epoch:    1/2     Loss: 4.502913591384888\n",
            "\n",
            "Epoch:    1/2     Loss: 4.473716244935989\n",
            "\n",
            "Epoch:    1/2     Loss: 4.46975279378891\n",
            "\n",
            "Epoch:    1/2     Loss: 4.459234530210495\n",
            "\n",
            "Epoch:    1/2     Loss: 4.442343366861343\n",
            "\n",
            "Epoch:    1/2     Loss: 4.458018887519836\n",
            "\n",
            "Epoch:    1/2     Loss: 4.4620258147716525\n",
            "\n",
            "Epoch:    1/2     Loss: 4.473200842380524\n",
            "\n",
            "Epoch:    1/2     Loss: 4.449359548330307\n",
            "\n",
            "Epoch:    1/2     Loss: 4.461273861408234\n",
            "\n",
            "Epoch:    1/2     Loss: 4.4421257417202\n",
            "\n",
            "Epoch:    1/2     Loss: 4.438751188993454\n",
            "\n",
            "Epoch:    1/2     Loss: 4.433604041814804\n",
            "\n",
            "Epoch:    1/2     Loss: 4.431796543359757\n",
            "\n",
            "Epoch:    1/2     Loss: 4.432647002220154\n",
            "\n",
            "Epoch:    1/2     Loss: 4.420109316825867\n",
            "\n",
            "Epoch:    1/2     Loss: 4.4179854245185854\n",
            "\n",
            "Epoch:    1/2     Loss: 4.412220306396485\n",
            "\n",
            "Epoch:    1/2     Loss: 4.408578038454055\n",
            "\n",
            "Epoch:    1/2     Loss: 4.4308995952606205\n",
            "\n",
            "Epoch:    1/2     Loss: 4.428287930727005\n",
            "\n",
            "Epoch:    1/2     Loss: 4.413624763011932\n",
            "\n",
            "Epoch:    1/2     Loss: 4.427152596473694\n",
            "\n",
            "Epoch:    1/2     Loss: 4.406517873287201\n",
            "\n",
            "Epoch:    1/2     Loss: 4.417320380449295\n",
            "\n",
            "Epoch:    1/2     Loss: 4.404170077562332\n",
            "\n",
            "Epoch:    1/2     Loss: 4.421220325231552\n",
            "\n",
            "Epoch:    1/2     Loss: 4.4051169557571415\n",
            "\n",
            "Epoch:    1/2     Loss: 4.421752342700958\n",
            "\n",
            "Epoch:    1/2     Loss: 4.409413376808167\n",
            "\n",
            "Epoch:    1/2     Loss: 4.391699395418167\n",
            "\n",
            "Epoch:    1/2     Loss: 4.410555418729782\n",
            "\n",
            "Epoch:    1/2     Loss: 4.427304629802704\n",
            "\n",
            "Epoch:    1/2     Loss: 4.418685782909393\n",
            "\n",
            "Epoch:    1/2     Loss: 4.402892759084701\n",
            "\n",
            "Epoch:    1/2     Loss: 4.40214652633667\n",
            "\n",
            "Epoch:    1/2     Loss: 4.412566684722901\n",
            "\n",
            "Epoch:    1/2     Loss: 4.389518516302108\n",
            "\n",
            "Epoch:    1/2     Loss: 4.394264532566071\n",
            "\n",
            "Epoch:    1/2     Loss: 4.3900729613304135\n",
            "\n",
            "Epoch:    1/2     Loss: 4.399749807357788\n",
            "\n",
            "Epoch:    1/2     Loss: 4.368818397521973\n",
            "\n",
            "Epoch:    1/2     Loss: 4.388294541120529\n",
            "\n",
            "Epoch:    1/2     Loss: 4.388266169309616\n",
            "\n",
            "Epoch:    1/2     Loss: 4.412054891347885\n",
            "\n",
            "Epoch:    1/2     Loss: 4.36887392282486\n",
            "\n",
            "Epoch:    1/2     Loss: 4.3843606526851655\n",
            "\n",
            "Epoch:    1/2     Loss: 4.400302296638489\n",
            "\n",
            "Epoch:    1/2     Loss: 4.367969244003296\n",
            "\n",
            "Epoch:    2/2     Loss: 4.343514781231168\n",
            "\n",
            "Epoch:    2/2     Loss: 4.31052099275589\n",
            "\n",
            "Epoch:    2/2     Loss: 4.329959261894226\n",
            "\n",
            "Epoch:    2/2     Loss: 4.349722977876663\n",
            "\n",
            "Epoch:    2/2     Loss: 4.334062855958939\n",
            "\n",
            "Epoch:    2/2     Loss: 4.321823816776275\n",
            "\n",
            "Epoch:    2/2     Loss: 4.311436013936996\n",
            "\n",
            "Epoch:    2/2     Loss: 4.337068397998809\n",
            "\n",
            "Epoch:    2/2     Loss: 4.342851005077362\n",
            "\n",
            "Epoch:    2/2     Loss: 4.316982578277588\n",
            "\n",
            "Epoch:    2/2     Loss: 4.332783488035202\n",
            "\n",
            "Epoch:    2/2     Loss: 4.340055213928222\n",
            "\n",
            "Epoch:    2/2     Loss: 4.343646999359131\n",
            "\n",
            "Epoch:    2/2     Loss: 4.312853673696518\n",
            "\n",
            "Epoch:    2/2     Loss: 4.336001517057419\n",
            "\n",
            "Epoch:    2/2     Loss: 4.328174949645996\n",
            "\n",
            "Epoch:    2/2     Loss: 4.337274574756623\n",
            "\n",
            "Epoch:    2/2     Loss: 4.327751150608063\n",
            "\n",
            "Epoch:    2/2     Loss: 4.335154892921448\n",
            "\n",
            "Epoch:    2/2     Loss: 4.322340563058853\n",
            "\n",
            "Epoch:    2/2     Loss: 4.340320106983185\n",
            "\n",
            "Epoch:    2/2     Loss: 4.337640731811524\n",
            "\n",
            "Epoch:    2/2     Loss: 4.321650958061218\n",
            "\n",
            "Epoch:    2/2     Loss: 4.328295777559281\n",
            "\n",
            "Epoch:    2/2     Loss: 4.327451582431793\n",
            "\n",
            "Epoch:    2/2     Loss: 4.323508269071579\n",
            "\n",
            "Epoch:    2/2     Loss: 4.358278146743775\n",
            "\n",
            "Epoch:    2/2     Loss: 4.335713473320007\n",
            "\n",
            "Epoch:    2/2     Loss: 4.323318859815598\n",
            "\n",
            "Epoch:    2/2     Loss: 4.329880468845367\n",
            "\n",
            "Epoch:    2/2     Loss: 4.339813157558441\n",
            "\n",
            "Epoch:    2/2     Loss: 4.320208687305451\n",
            "\n",
            "Epoch:    2/2     Loss: 4.328880975484848\n",
            "\n",
            "Epoch:    2/2     Loss: 4.339027513504028\n",
            "\n",
            "Epoch:    2/2     Loss: 4.331601974725723\n",
            "\n",
            "Epoch:    2/2     Loss: 4.353878479003907\n",
            "\n",
            "Epoch:    2/2     Loss: 4.335790751218796\n",
            "\n",
            "Epoch:    2/2     Loss: 4.309684445619583\n",
            "\n",
            "Epoch:    2/2     Loss: 4.341310850381851\n",
            "\n",
            "Epoch:    2/2     Loss: 4.332097621202469\n",
            "\n",
            "Epoch:    2/2     Loss: 4.329447386741638\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3356752824783324\n",
            "\n",
            "Epoch:    2/2     Loss: 4.33291440820694\n",
            "\n",
            "Epoch:    2/2     Loss: 4.342060493946075\n",
            "\n",
            "Epoch:    2/2     Loss: 4.327351857662201\n",
            "\n",
            "Epoch:    2/2     Loss: 4.324620166063308\n",
            "\n",
            "Epoch:    2/2     Loss: 4.32801084113121\n",
            "\n",
            "Epoch:    2/2     Loss: 4.305682844161987\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3646922216415405\n",
            "\n",
            "Epoch:    2/2     Loss: 4.339284910678863\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3335223863124845\n",
            "\n",
            "Epoch:    2/2     Loss: 4.339551343679428\n",
            "\n",
            "Epoch:    2/2     Loss: 4.343731967926026\n",
            "\n",
            "Epoch:    2/2     Loss: 4.32693732047081\n",
            "\n",
            "Epoch:    2/2     Loss: 4.333780776500702\n",
            "\n",
            "Epoch:    2/2     Loss: 4.330474179267883\n",
            "\n",
            "Epoch:    2/2     Loss: 4.332786418914795\n",
            "\n",
            "Epoch:    2/2     Loss: 4.348149967432022\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3196819393634796\n",
            "\n",
            "Epoch:    2/2     Loss: 4.327660020589828\n",
            "\n",
            "Epoch:    2/2     Loss: 4.332141847133636\n",
            "\n",
            "Epoch:    2/2     Loss: 4.348808676958084\n",
            "\n",
            "Epoch:    2/2     Loss: 4.312914789438247\n",
            "\n",
            "Epoch:    2/2     Loss: 4.33737946152687\n",
            "\n",
            "Epoch:    2/2     Loss: 4.332126477956772\n",
            "\n",
            "Epoch:    2/2     Loss: 4.326302766561509\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3193377821445464\n",
            "\n",
            "Epoch:    2/2     Loss: 4.320331514596939\n",
            "\n",
            "Epoch:    2/2     Loss: 4.338366815805435\n",
            "\n",
            "Epoch:    2/2     Loss: 4.319152268648147\n",
            "\n",
            "Epoch:    2/2     Loss: 4.34363768529892\n",
            "\n",
            "Epoch:    2/2     Loss: 4.3354903681278225\n",
            "\n",
            "Epoch:    2/2     Loss: 4.31272775554657\n",
            "\n",
            "Epoch:    2/2     Loss: 4.321514741897583\n",
            "\n",
            "Epoch:    2/2     Loss: 4.336042956113816\n",
            "\n",
            "Model Trained and Saved\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "if train_on_gpu:\n",
        "    rnn.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
        "\n",
        "helper.save_model('./save/trained_rnn', trained_rnn)\n",
        "print('Model Trained and Saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "guc2x6c4qcgwvwc4yb9ts",
        "id": "Itd0tquYJQS6"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "import torch\n",
        "import helper\n",
        "import problem_unittests as tests\n",
        "\n",
        "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
        "trained_rnn = helper.load_model('./save/trained_rnn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "b5vczn6zug969oz0e0npwd",
        "id": "yqaBoM_zJQS6"
      },
      "source": [
        "## Generate TV Script\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "89o9dyzvdjtoxsga2y76",
        "id": "BWPM7gLKJQS6"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
        "    rnn.eval()\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        if train_on_gpu:\n",
        "            current_seq = torch.LongTensor(current_seq).cuda()\n",
        "        else:\n",
        "            current_seq = torch.LongTensor(current_seq)\n",
        "        hidden = rnn.init_hidden(current_seq.size(0))\n",
        "\n",
        "        output, _ = rnn(current_seq, hidden)\n",
        "\n",
        "        p = F.softmax(output, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu()\n",
        "\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.numpy().squeeze()\n",
        "\n",
        "        p = p.numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "\n",
        "        current_seq = np.roll(current_seq.cpu(), -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    for key, token in token_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    \n",
        "    return gen_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "sm9mlj2xniq2t7q5noklnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-8KCYfbJQS7",
        "outputId": "a8f04adb-36e7-4978-c2ba-98bebb397c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jeff:\n",
            "hair.\n",
            "\n",
            "he walks to the door and looks back at his.\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. bathroom- night\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. the house\n",
            "\n",
            "the two men sit on the edge of the stairs, staring at him.\n",
            "\n",
            "\n",
            "int. hotel lobby- day\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. the car- night(flashback)\n",
            "\n",
            "the door is a dark.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. kitchen- night\n",
            "\n",
            "\n",
            "\n",
            "int. hotel room, kitchen\n",
            "\n",
            "as they walk through the crowd of the house of\n",
            "the door.\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "int. the room, night\n",
            "\n",
            "the camera pans on a few feet in the doorway,\n",
            "\n",
            "he turns to the other. she looks at him,\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "ext. a house- night\n",
            "\n",
            "a large black man is standing at the door, and\n",
            "she sees the woman, and his wife\n",
            "\n",
            "\n",
            "(more)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. gotham street- night\n",
            "\n",
            "the car is in the dark, the sun is a\n",
            "little...\n",
            "\n",
            "\n",
            "ext. highway- day- day- later-\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. dirigible.\n",
            "\n",
            "the camera pans in, the door.\n",
            "\n",
            "\n",
            "int. hotel room\n",
            "\n",
            "a large man in the middle, the car is a very\n",
            "little.\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "int. hotel lobby- day\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. the kitchen- day\n",
            "\n",
            "the man is standing in the living room.\n",
            "\n",
            "the two men look at each other.\n",
            "\n",
            "\n",
            "int. kitchen- day\n",
            "\n",
            "the car is dark, and he is on the bed\n",
            "and a large.\n",
            "(to the woman)\n",
            "you know what i mean?\n",
            "\n",
            "\n",
            "ext. beach- day\n",
            "\n",
            "the door is dark as a man and the other.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\" wild hogs\" writers first draft 7/06/05 58.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. hotel room\n",
            "\n",
            "the camera is on the floor, and the other\n",
            "other are a large man in the middle of the\n",
            "room.\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "int. the car, day\n",
            "\n",
            "the camera pulls back to the kitchen, and the other\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "int. jeff's apartment- day- closeup\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. street- night\n",
            "\n",
            "the car pulls out the door and opens the door.\n",
            "\n",
            "\n",
            "int. the kitchen\n",
            "\n",
            "the door closes.\n",
            "\n",
            "\n",
            "int. kitchen, bedroom- day\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. kitchen, mckenna and lotte's bedroom- day\n",
            "\n",
            "a small figure and a man who are sitting on the floor\n",
            "of the kitchen.\n",
            "\n",
            "\n",
            "int. hotel lobby- night\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the two men are waiting for a beat.\n",
            "\n",
            "\n",
            "ext. street- night\n",
            "\n",
            "\n",
            "\n",
            "int. dussander's house- night- later\n",
            "\n",
            "the camera pans on the door.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4th blue revisions 03- 26- 10 57.\n",
            "\n",
            "\n",
            "int. jeff's home- night- closeup\n",
            "\n",
            "a beat...\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "int. kitchen\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. the streets-- day\n",
            "\n",
            "the two of them have a little bit\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the fighter 8/28/09 green draft 54.\n",
            "\n",
            "\n",
            "(a beat)\n",
            "\n",
            "\n",
            "(to himself)\n",
            "i'm sorry, i think.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "carl\n",
            "i know.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the camera pulls back to reveal, a small-\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the fighter 8/28/09 green draft 46,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(continued)\n",
            "pink revision- 11/12/06 9.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "the man\n",
            "\n",
            "(to the woman)\n",
            "you have to be a little more.\n",
            "\n",
            "\n",
            "int. jeff's apartment- day- closeup\n",
            "\n",
            "jeff and the others stand at the front door behind\n",
            "him.\n",
            "\n",
            "\n",
            "int. jeff's apartment- night- semi- closeup\n",
            "\n",
            "jeff, in his hand.\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "ext.- day\n",
            "\n",
            "\n",
            "the camera pans in the room, a few feet away from the\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the fighter 8/28/09 green draft 57.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. street- night\n",
            "\n",
            "the car comes in.\n",
            "\n",
            "\n",
            "ext. street, gotham road-- night\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the man, in a small robe. the two men look at the\n",
            "ceiling.\n",
            "\n",
            "\n",
            "ext. the road- continuous\n",
            "\n",
            "the two cars look down the street toward each\n",
            "other, and the two men.\n",
            "\n",
            "\n",
            "cut to:\n",
            "\n",
            "\n",
            "ext. street, night\n",
            "\n",
            "as he passes, a large figure is sitting with a man, a\n",
            "young man.\n",
            "the two men laugh and then, he sees his\n",
            "eyes.\n",
            "\n",
            "\n",
            "int. hallway- day\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "(more)\n",
            "\n",
            "\n",
            "(continued)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. the field- night\n",
            "\n",
            "the car is a little bit of the man.\n",
            "\n",
            "\n",
            "ext. neighborhood- night- semi- long shot\n",
            "\n",
            "jeff and george sit at the table, watching the\n",
            "other side of the room.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "int. solatano bedroom, bathroom- night\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ext. suburban house- day\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the door is opened by a man, his eyes, his eyes wide, he sees a\n",
            "\n",
            "\n",
            "voice- in\n",
            "\n",
            "\n",
            "(more)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "continued:\n",
            "\n",
            "\n",
            "ext. the road- day\n",
            "\n",
            "a small man sits in a large- chair with his hands.\n",
            "\n",
            "\n",
            "int. kitchen\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!g2.mig\n",
        "gen_length = 2000\n",
        "prime_word = 'jeff'\n",
        "\n",
        "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
        "generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
        "print(generated_script)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "m7xgj8vnsjlgzu0bqk8qe6",
        "id": "P-Fy5dVZJQS8"
      },
      "source": [
        "#### Save your favorite scripts\n",
        "\n",
        "Once you have a script that you like (or find interesting), save it to a text file!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "zkzc9oock7hau05fqielll",
        "id": "dDDeOmKVJQS8"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n",
        "# save script to a text file\n",
        "f = open(\"generated_script_1.txt\",\"w\")\n",
        "f.write(generated_script)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "v2q7w6dy51aanpgt0b8rtn",
        "id": "XfZ6tUaDpDmg"
      },
      "outputs": [],
      "source": [
        "#!g2.mig\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    },
    "notebookId": "f5675bf6-be40-49bc-b898-0776c814ee79",
    "notebookPath": "NIS_15_02.ipynb",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}