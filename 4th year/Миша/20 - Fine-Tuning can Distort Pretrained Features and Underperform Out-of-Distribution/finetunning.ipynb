{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "vre50rqr5vg8ykfifhasi",
        "id": "ZZkWU8STjQdG"
      },
      "source": [
        "## Грузим библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "djfr399yoifbkw2mrsn4y8",
        "id": "S3UEdXbnbvml",
        "outputId": "7c9818d3-3717-40da-837c-1fafe0061b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.14.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /kernel/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.3.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.11.10)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.3)\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "     |████████████████████████████████| 451 kB 1.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: xxhash in /kernel/fallback/lib/python3.8/site-packages (from datasets) (2.0.0)\n",
            "Collecting tqdm>=4.62.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "     |████████████████████████████████| 78 kB 3.9 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /kernel/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.10.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.2.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.3.1)\n",
            "Collecting pyarrow>=6.0.0\n",
            "  Downloading pyarrow-10.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.0 MB)\n",
            "     |████████████████████████████████| 36.0 MB 6.5 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from datasets) (1.19.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.11.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "     |████████████████████████████████| 132 kB 8.1 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: packaging in /kernel/lib/python3.8/site-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (0.25.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from responses<0.19->datasets) (1.16.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.0.9)\n",
            "Collecting dill<0.3.7\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "     |████████████████████████████████| 110 kB 8.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /kernel/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.3)\n",
            "Installing collected packages: tqdm, dill, pyarrow, multiprocess, datasets\n",
            "\u001b[33m  WARNING: The script tqdm is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipystate 0.0.1 requires pyarrow<=5.0.0,>=0.17.1, but you have pyarrow 10.0.1 which is incompatible.\n",
            "kaggle 1.5.8 requires urllib3<1.25,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\n",
            "cloud-ml 0.0.1 requires tqdm<=4.54.1,>=4.45.0, but you have tqdm 4.64.1 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-2.7.1 dill-0.3.6 multiprocess-0.70.14 pyarrow-10.0.1 tqdm-4.64.1\n",
            "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "z5623awvm7hq26pdz64sif",
        "id": "VTsU6yrOjUo7"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "va9o0tgpmcyl9aqscve1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "d67844316fdd4d04a27196dcb2fac506",
            "d7c0fa59de874b209d69a32fca9ad1d1",
            "7d733c5fa15c47b5adc833a08ffe38be",
            "69a200f2775b46bf8c1b093263368b02",
            "3227260387c64e2792cb56b9528c83cf",
            "2cd415b301bc4b7eab8abb91a09753fa",
            "9b58fbdb6f7b43eebbc1c7ccf6a5fdf4",
            "e5fee55daf514a52bf5d7be48cadf26d",
            "fb110f7b2ecb4d64bb8c983acce11c9f",
            "e2dbcd68188c47d898b0d11a168eb59e",
            "6c3b02c739934535ac7e3bb895cf941f",
            "924af99340f0491cb022d79e76517600",
            "8029a90fca92408abafbaa47a412e14b",
            "df8605f766cd489eae8f8fda54f46f12",
            "9e4bf4b59fb44ce3a1247da5cc465d4a",
            "e167a651ae994180ae2c29ea472feacc",
            "672aa4360f5748debf823264dd724cad",
            "f833fa3adfc0433094a10ff46d205170",
            "d34cd9e392dc4564a244292b49d8a1c1",
            "342878d1d20d40a793a0d73b3abc6768"
          ]
        },
        "id": "IqobrJcMevea",
        "outputId": "e3100eef-f938-4739-ddb7-79bb3c59f04c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "924af99340f0491cb022d79e76517600",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.64k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8029a90fca92408abafbaa47a412e14b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df8605f766cd489eae8f8fda54f46f12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e4bf4b59fb44ce3a1247da5cc465d4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/143M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e167a651ae994180ae2c29ea472feacc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files #0:   0%|          | 0/1 [00:00<?, ?obj/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "672aa4360f5748debf823264dd724cad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files #1:   0%|          | 0/1 [00:00<?, ?obj/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f833fa3adfc0433094a10ff46d205170",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d34cd9e392dc4564a244292b49d8a1c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset kinopoisk/simple to /tmp/xdg_cache/huggingface/datasets/blinoff___kinopoisk/simple/1.0.0/62f52027aea59f64f49c7b16165b82cb4dc45031bad3660c2719bf2a6ea4a44e...\n",
            "  Dataset kinopoisk downloaded and prepared to /tmp/xdg_cache/huggingface/datasets/blinoff___kinopoisk/simple/1.0.0/62f52027aea59f64f49c7b16165b82cb4dc45031bad3660c2719bf2a6ea4a44e. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "342878d1d20d40a793a0d73b3abc6768",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!g1.1\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('blinoff/kinopoisk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "do1wb09prrvq2joqi815ss",
        "id": "iPeSC_-ofGjU"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_texts(texts):\n",
        "    res = []\n",
        "    for t in texts:\n",
        "        res.append(t.strip().replace('\\n', ' '))\n",
        "    return res\n",
        "\n",
        "df = pd.DataFrame({'text': prepare_texts(dataset['train']['content']), 'grade': dataset['train']['grade3']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "59k3oi56ttrbbsvnm1oaus",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BtGhd_Amgwvx",
        "outputId": "784a1df7-561e-416c-b0a0-cccbac92d24c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Блеф» — одна из моих самых любимых комедий.  ...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Адриано Челентано продолжает радовать нас свои...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Несомненно, это один из великих фильмов 80-х г...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Эта фраза на мой взгляд отражает сюжет несомне...</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>- как пела Земфира, скорее всего, по совершенн...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    grade\n",
              "0  \"Блеф» — одна из моих самых любимых комедий.  ...     Good\n",
              "1  Адриано Челентано продолжает радовать нас свои...     Good\n",
              "2  Несомненно, это один из великих фильмов 80-х г...     Good\n",
              "3  Эта фраза на мой взгляд отражает сюжет несомне...     Good\n",
              "4  - как пела Земфира, скорее всего, по совершенн...  Neutral"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!g1.1\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "njzmp0vdm60w3piiqiysz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHKkKkdqinub",
        "outputId": "444aebd7-c430-4f56-9848-dbf40c96f51e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Good       27264\n",
              "Bad         4751\n",
              "Neutral     4576\n",
              "Name: grade, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!g1.1\n",
        "df['grade'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "vgx1pt54mehrifbnhu0uo",
        "id": "zjeflxWFipVF"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "id2label = ['Good', 'Neutral', 'Bad']\n",
        "labels2id = {label: i for i, label in enumerate(id2label)}\n",
        "\n",
        "df['label'] = df['grade'].apply(lambda x: labels2id[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "0dk4y44nqyqiewwbtethbcl",
        "id": "EgxfcVq3jizr"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['text'].to_numpy(), df['label'].to_numpy(), test_size=0.2, random_state=42, shuffle=True, stratify=df['label'].to_numpy())\n",
        "x_str, x_nstr, y_str, y_nstr = train_test_split(x_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "04wkun8mb0hu0gfaw3kjxl7a",
        "id": "JQXFguZazbFI",
        "outputId": "942f2d63-60b7-4640-8ba9-e4f522be0c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count of 0 in distribution:\t 2727 \t count of 0 out of distribution:\t 136\n",
            "Count of 1 in distribution:\t 457 \t count of 1 out of distribution:\t 458\n",
            "Count of 2 in distribution:\t 475 \t count of 2 out of distribution:\t 475\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "import numpy as np\n",
        "\n",
        "def get_data_not_stratifyed(x, y):\n",
        "    y_tmp_0 = y[y == 0]\n",
        "    x_tmp_0 = x[y == 0]\n",
        "    y_tmp_n_0 = y[y != 0]\n",
        "    x_tmp_n_0 = x[y != 0]\n",
        "    length_0 = len(y_tmp_0) // 20\n",
        "    return np.concatenate((x_tmp_0[:length_0], x_tmp_n_0)), np.concatenate((y_tmp_0[:length_0], y_tmp_n_0))\n",
        "\n",
        "\n",
        "x_nstr, y_nstr = get_data_not_stratifyed(x_nstr, y_nstr)\n",
        "\n",
        "print('Count of 0 in distribution:\\t', len(y_str[y_str == 0]), '\\t count of 0 out of distribution:\\t', len(y_nstr[y_nstr == 0]))\n",
        "print('Count of 1 in distribution:\\t', len(y_str[y_str == 1]), '\\t count of 1 out of distribution:\\t', len(y_nstr[y_nstr == 1]))\n",
        "print('Count of 2 in distribution:\\t', len(y_str[y_str == 2]), '\\t count of 2 out of distribution:\\t', len(y_nstr[y_nstr == 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "ye6wpe71jbajlet0enwhrb",
        "execution_id": "c7f84dc6-2a3a-408a-8c05-006fb8865fac",
        "id": "V43g_77cjZEW"
      },
      "source": [
        "## Код для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "9stbrj7xnxpibuye8zx4b",
        "id": "zKFEyjf5b1LQ",
        "outputId": "802b0d49-92aa-4cea-dba9-89622b5001d7",
        "colab": {
          "referenced_widgets": [
            "3052807d4dca49b68507cfede72e153c",
            "bb132467d4674f75b4dd09f9dca85362",
            "a98e4db8a3554c5b9db29727e7abc8af",
            "9686902ef15048c4b775dda5fdcd403e",
            "88159d18225645a190bb189d2741af99"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3052807d4dca49b68507cfede72e153c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/341 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb132467d4674f75b4dd09f9dca85362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/632 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a98e4db8a3554c5b9db29727e7abc8af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9686902ef15048c4b775dda5fdcd403e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/457k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88159d18225645a190bb189d2741af99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!g1.1\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "5asmv8tfgj76bht1l02a54",
        "id": "2FI61-PTm5I3"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class KinopoiskDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, device=torch.device('cpu')):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.labels = labels\n",
        "        self.device = device\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, return_tensors='pt')\n",
        "        return {k: v.to(self.device).flatten() for k, v in tokens.items()}, torch.tensor(self.labels[idx]).to(self.device)\n",
        "\n",
        "train_dataset = KinopoiskDataset(x_train.tolist(), y_train.tolist(), tokenizer, device=device)\n",
        "str_dataset = KinopoiskDataset(x_str.tolist(), y_str.tolist(), tokenizer, device=device)\n",
        "nstr_dataset = KinopoiskDataset(x_nstr.tolist(), y_nstr.tolist(), tokenizer, device=device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "str_loader = DataLoader(str_dataset, batch_size=BATCH_SIZE)\n",
        "nstr_loader = DataLoader(nstr_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "jbilr8uecm9vhvipp13gil",
        "id": "ntu3zbL1j-pi"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "import torch.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(train_loader):\n",
        "        outputs = model(**x)\n",
        "        loss = criterion(outputs.logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for x, y in test_loader:\n",
        "        outputs = model(**x)\n",
        "        loss = criterion(outputs.logits, y)\n",
        "        total_loss += loss.item()\n",
        "        y_true.extend(y.tolist())\n",
        "        y_pred.extend(torch.argmax(outputs.logits, dim=1).tolist())\n",
        "\n",
        "    return total_loss / len(test_loader), accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "def train_epochs(model, train_loader, test_loader_str, test_loader_nstr, optimizer, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train(model, train_loader, optimizer)\n",
        "        print('Epoch', epoch)\n",
        "        print('Train loss:\\t', train_loss)\n",
        "        test_loss, test_acc = evaluate(model, test_loader_str)\n",
        "        print('Test loss ID:\\t', test_loss, '\\tTest acc ID:\\t', test_acc)\n",
        "        test_loss, test_acc = evaluate(model, test_loader_nstr)\n",
        "        print('Test loss OOD:\\t', test_loss, '\\tTest acc OOD:\\t', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "8zze22mvyq7r34as9o2ca",
        "id": "ShTnho_qzbFK"
      },
      "outputs": [],
      "source": [
        "#!g1.1\n",
        "def freeze_embeddings(model):\n",
        "    params = list(model.bert.embeddings.parameters())\n",
        "    for i, param in enumerate(params):\n",
        "        if i == len(params) - 1:\n",
        "            return\n",
        "\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "def unfreeze_embeddings(model):\n",
        "    for param in model.bert.embeddings.parameters():\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "v0rnn1drrjfy749jpsr3e",
        "execution_id": "8508ac96-55e1-4f8e-bccb-1f70dcd40766",
        "id": "YmtF5M7f0nd6"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "hqlo8xr0kq92622q5q5kdx",
        "execution_id": "ed524c62-4531-4966-a7e8-2f48d4d6626d",
        "id": "8j8O3nJViffq"
      },
      "source": [
        "## lr = 3e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "ncr4263kc8mj6vvuyoyer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-T9H3tzbFK",
        "outputId": "b4c2a361-b392-4e9e-a4c9-d4d2e5dbb91b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.77it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.77it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.77it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.77it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.597517860375467\n",
            "Test loss ID:\t 0.5154306884693063 \tTest acc ID:\t 0.8045914184203334\n",
            "Test loss OOD:\t 1.2572726519668804 \tTest acc OOD:\t 0.4667913938260056\n",
            "Epoch 1\n",
            "Train loss:\t 0.5001001001544337\n",
            "Test loss ID:\t 0.5227222008549649 \tTest acc ID:\t 0.8108772888767423\n",
            "Test loss OOD:\t 1.417731615659945 \tTest acc OOD:\t 0.43405051449953225\n",
            "Epoch 2\n",
            "Train loss:\t 0.4705772715025261\n",
            "Test loss ID:\t 0.506436587675758 \tTest acc ID:\t 0.80896419786827\n",
            "Test loss OOD:\t 1.350017574889695 \tTest acc OOD:\t 0.45650140318054255\n",
            "Epoch 3\n",
            "Train loss:\t 0.4516633277138074\n",
            "Test loss ID:\t 0.4992341203534085 \tTest acc ID:\t 0.8108772888767423\n",
            "Test loss OOD:\t 1.2579573545166676 \tTest acc OOD:\t 0.47895229186155286\n",
            "Epoch 4\n",
            "Train loss:\t 0.43514135798307063\n",
            "Test loss ID:\t 0.505113650534464 \tTest acc ID:\t 0.8070511068597978\n",
            "Test loss OOD:\t 1.28718791124137 \tTest acc OOD:\t 0.46024321796071094\n",
            "Epoch 5\n",
            "Train loss:\t 0.42189645414632526\n",
            "Test loss ID:\t 0.4936322160389112 \tTest acc ID:\t 0.8136102760317027\n",
            "Test loss OOD:\t 1.216825466383906 \tTest acc OOD:\t 0.4883068288119738\n",
            "Epoch 6\n",
            "Train loss:\t 0.40842027040452905\n",
            "Test loss ID:\t 0.5267465389293173 \tTest acc ID:\t 0.808417600437278\n",
            "Test loss OOD:\t 1.3321386616238777 \tTest acc OOD:\t 0.4714686623012161\n",
            "Epoch 7\n",
            "Train loss:\t 0.39715457719043307\n",
            "Test loss ID:\t 0.5107942093325698 \tTest acc ID:\t 0.8095107952992621\n",
            "Test loss OOD:\t 1.2089833818814333 \tTest acc OOD:\t 0.5266604303086997\n",
            "Epoch 8\n",
            "Train loss:\t 0.38780559589628316\n",
            "Test loss ID:\t 0.5347454748075942 \tTest acc ID:\t 0.8067778081443017\n",
            "Test loss OOD:\t 1.2230069662499077 \tTest acc OOD:\t 0.5509822263797942\n",
            "Epoch 9\n",
            "Train loss:\t 0.37502135775698336\n",
            "Test loss ID:\t 0.55049329166827 \tTest acc ID:\t 0.8073244055752938\n",
            "Test loss OOD:\t 1.3730806837625362 \tTest acc OOD:\t 0.49859681945743684\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "freeze_embeddings(model)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "d4d35nov59j0yh341gr",
        "id": "0Lo7l0VB6y7H",
        "outputId": "3c2a161e-fee8-4e4f-8494-155b3ffdf1d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.50it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.50it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.50it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.50it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.50it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.5376327929112429\n",
            "Test loss ID:\t 0.4556072084800057 \tTest acc ID:\t 0.8196228477726155\n",
            "Test loss OOD:\t 1.0780626081806772 \tTest acc OOD:\t 0.5266604303086997\n",
            "Epoch 1\n",
            "Train loss:\t 0.422198479296894\n",
            "Test loss ID:\t 0.4983040225246678 \tTest acc ID:\t 0.8190762503416233\n",
            "Test loss OOD:\t 1.308023927075898 \tTest acc OOD:\t 0.5126286248830683\n",
            "Epoch 2\n",
            "Train loss:\t 0.3539936543325257\n",
            "Test loss ID:\t 0.5681606997614321 \tTest acc ID:\t 0.816069964471167\n",
            "Test loss OOD:\t 1.5187118715223145 \tTest acc OOD:\t 0.5173058933582788\n",
            "Epoch 3\n",
            "Train loss:\t 0.29062927213645046\n",
            "Test loss ID:\t 0.6325391137081644 \tTest acc ID:\t 0.8065045094288057\n",
            "Test loss OOD:\t 1.6023894910536267 \tTest acc OOD:\t 0.5126286248830683\n",
            "Epoch 4\n",
            "Train loss:\t 0.24022004318835793\n",
            "Test loss ID:\t 0.6906029000878334 \tTest acc ID:\t 0.7947526646624761\n",
            "Test loss OOD:\t 1.5793677583775099 \tTest acc OOD:\t 0.5509822263797942\n",
            "Epoch 5\n",
            "Train loss:\t 0.19640631518158758\n",
            "Test loss ID:\t 0.7379461337690768 \tTest acc ID:\t 0.7906531839300355\n",
            "Test loss OOD:\t 2.0150317852111423 \tTest acc OOD:\t 0.47988774555659497\n",
            "Epoch 6\n",
            "Train loss:\t 0.15997533185173415\n",
            "Test loss ID:\t 0.8550484111937492 \tTest acc ID:\t 0.7906531839300355\n",
            "Test loss OOD:\t 2.1903807792593453 \tTest acc OOD:\t 0.48175865294667913\n",
            "Epoch 7\n",
            "Train loss:\t 0.13636954705449728\n",
            "Test loss ID:\t 0.8586482727657194 \tTest acc ID:\t 0.7786280404482099\n",
            "Test loss OOD:\t 2.1194428402711365 \tTest acc OOD:\t 0.49672591206735267\n",
            "Epoch 8\n",
            "Train loss:\t 0.10920081303195386\n",
            "Test loss ID:\t 0.8639645172202068 \tTest acc ID:\t 0.7772615468707297\n",
            "Test loss OOD:\t 2.2031239648075664 \tTest acc OOD:\t 0.490177736202058\n",
            "Epoch 9\n",
            "Train loss:\t 0.08784469470961905\n",
            "Test loss ID:\t 0.9488230745429578 \tTest acc ID:\t 0.7917463787920197\n",
            "Test loss OOD:\t 2.393322033150231 \tTest acc OOD:\t 0.4855004677268475\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "u98bkj8153a1lhc3dfu2ne",
        "id": "1Htxghax61In",
        "outputId": "dd1cdcc2-e5b7-4772-befa-2d0b6db04438"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:39<00:00,  5.75it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.77it/s]\n",
            "100%|██████████| 915/915 [02:39<00:00,  5.75it/s]\n",
            "100%|██████████| 915/915 [02:39<00:00,  5.75it/s]\n",
            "100%|██████████| 915/915 [02:38<00:00,  5.76it/s]\n",
            "100%|██████████| 915/915 [02:45<00:00,  5.52it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:45<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:46<00:00,  5.51it/s]\n",
            "100%|██████████| 915/915 [02:45<00:00,  5.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.5840054696212049\n",
            "Test loss ID:\t 0.5122990868661714 \tTest acc ID:\t 0.8051380158513255\n",
            "Test loss OOD:\t 1.290705388302312 \tTest acc OOD:\t 0.4106641721234799\n",
            "Epoch 1\n",
            "Train loss:\t 0.4982157230214343\n",
            "Test loss ID:\t 0.48452109318712483 \tTest acc ID:\t 0.8127903798852145\n",
            "Test loss OOD:\t 1.2178758608506006 \tTest acc OOD:\t 0.43592142188961647\n",
            "Epoch 2\n",
            "Train loss:\t 0.471726274164648\n",
            "Test loss ID:\t 0.479478483096413 \tTest acc ID:\t 0.8174364580486472\n",
            "Test loss OOD:\t 1.152577225557145 \tTest acc OOD:\t 0.4920486435921422\n",
            "Epoch 3\n",
            "Train loss:\t 0.4515916393102844\n",
            "Test loss ID:\t 0.48232384609139484 \tTest acc ID:\t 0.8155233670401749\n",
            "Test loss OOD:\t 1.2647453596925033 \tTest acc OOD:\t 0.45088868101029\n",
            "Epoch 4\n",
            "Train loss:\t 0.43412431943449165\n",
            "Test loss ID:\t 0.49058618765810263 \tTest acc ID:\t 0.8155233670401749\n",
            "Test loss OOD:\t 1.1468411567894852 \tTest acc OOD:\t 0.510757717492984\n",
            "Epoch 0\n",
            "Train loss:\t 0.44992196863629125\n",
            "Test loss ID:\t 0.4973970712526985 \tTest acc ID:\t 0.8073244055752938\n",
            "Test loss OOD:\t 1.1416410985676682 \tTest acc OOD:\t 0.5332086061739943\n",
            "Epoch 1\n",
            "Train loss:\t 0.3929135408964965\n",
            "Test loss ID:\t 0.5068149455863497 \tTest acc ID:\t 0.8106039901612463\n",
            "Test loss OOD:\t 1.2597704253652517 \tTest acc OOD:\t 0.5229186155285314\n",
            "Epoch 2\n",
            "Train loss:\t 0.3441397595193868\n",
            "Test loss ID:\t 0.5349953843199688 \tTest acc ID:\t 0.8100573927302541\n",
            "Test loss OOD:\t 1.2999385439736002 \tTest acc OOD:\t 0.5369504209541628\n",
            "Epoch 3\n",
            "Train loss:\t 0.27634262671398985\n",
            "Test loss ID:\t 0.6316646157399468 \tTest acc ID:\t 0.8051380158513255\n",
            "Test loss OOD:\t 1.7468896372353329 \tTest acc OOD:\t 0.48362956033676335\n",
            "Epoch 4\n",
            "Train loss:\t 0.22636549480544413\n",
            "Test loss ID:\t 0.712861927955047 \tTest acc ID:\t 0.8100573927302541\n",
            "Test loss OOD:\t 2.114082080695559 \tTest acc OOD:\t 0.45275958840037417\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "freeze_embeddings(model)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 5)\n",
        "\n",
        "unfreeze_embeddings(model)\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "6auugx72rr8v5dk0xeueea",
        "execution_id": "2fe21df7-5662-4d0f-8bd9-0a4346f7b334",
        "id": "TvFgjyf-iffr"
      },
      "source": [
        "## lr = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "fcpdo1dsosa4jdyqvq58qk",
        "execution_id": "d5fd5d75-4d78-40d2-86c0-3d5fccb3eaae",
        "id": "w-2YoEtXiffr",
        "outputId": "755f296c-b341-4dde-87b2-2aa2e13963b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.67it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.69it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.67it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n",
            "100%|██████████| 915/915 [02:41<00:00,  5.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.5649307834646089\n",
            "Test loss ID:\t 0.48659713747708694 \tTest acc ID:\t 0.80896419786827\n",
            "Test loss OOD:\t 1.1942725164048813 \tTest acc OOD:\t 0.44808231992516373\n",
            "Epoch 1\n",
            "Train loss:\t 0.4785665628688583\n",
            "Test loss ID:\t 0.47001336579737457 \tTest acc ID:\t 0.8168898606176551\n",
            "Test loss OOD:\t 1.1656181273214958 \tTest acc OOD:\t 0.4855004677268475\n",
            "Epoch 2\n",
            "Train loss:\t 0.4487028376977952\n",
            "Test loss ID:\t 0.4719176778326864 \tTest acc ID:\t 0.8152500683246788\n",
            "Test loss OOD:\t 1.1323596083504313 \tTest acc OOD:\t 0.5070159027128157\n",
            "Epoch 3\n",
            "Train loss:\t 0.42345910031613104\n",
            "Test loss ID:\t 0.46858665087948675 \tTest acc ID:\t 0.8223558349275758\n",
            "Test loss OOD:\t 1.1329650116317413 \tTest acc OOD:\t 0.5116931711880262\n",
            "Epoch 4\n",
            "Train loss:\t 0.40141297424914407\n",
            "Test loss ID:\t 0.4725770688575247 \tTest acc ID:\t 0.8198961464881115\n",
            "Test loss OOD:\t 1.0961273750838112 \tTest acc OOD:\t 0.5463049579045838\n",
            "Epoch 5\n",
            "Train loss:\t 0.37803025704915405\n",
            "Test loss ID:\t 0.48766616200623303 \tTest acc ID:\t 0.82344902978956\n",
            "Test loss OOD:\t 1.1499569650520296 \tTest acc OOD:\t 0.538821328344247\n",
            "Epoch 6\n",
            "Train loss:\t 0.35434122006586993\n",
            "Test loss ID:\t 0.5204808603810227 \tTest acc ID:\t 0.8201694452036076\n",
            "Test loss OOD:\t 1.294396129601142 \tTest acc OOD:\t 0.5210477081384471\n",
            "Epoch 7\n",
            "Train loss:\t 0.3328076476607818\n",
            "Test loss ID:\t 0.5306411675784899 \tTest acc ID:\t 0.8133369773162066\n",
            "Test loss OOD:\t 1.3411874842336948 \tTest acc OOD:\t 0.5229186155285314\n",
            "Epoch 8\n",
            "Train loss:\t 0.3027506275825162\n",
            "Test loss ID:\t 0.5872599650984225 \tTest acc ID:\t 0.8144301721781908\n",
            "Test loss OOD:\t 1.556725203662234 \tTest acc OOD:\t 0.4976613657623948\n",
            "Epoch 9\n",
            "Train loss:\t 0.2812602490919535\n",
            "Test loss ID:\t 0.619156639472298 \tTest acc ID:\t 0.8045914184203334\n",
            "Test loss OOD:\t 1.5223932914874132 \tTest acc OOD:\t 0.5229186155285314\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "freeze_embeddings(model)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "husza9zhx17tksf9most6p",
        "execution_id": "f651869a-5d37-4bd4-be4d-7f4ecfc755ec",
        "id": "w7QQ4FTKiffr",
        "outputId": "05a02928-cc0f-4fa3-a6fe-c6bb1a6f5c87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.46it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.46it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.5346942067797719\n",
            "Test loss ID:\t 0.45297387825406116 \tTest acc ID:\t 0.8261820169445203\n",
            "Test loss OOD:\t 1.0947292451472843 \tTest acc OOD:\t 0.5051449953227315\n",
            "Epoch 1\n",
            "Train loss:\t 0.41374693624471703\n",
            "Test loss ID:\t 0.4648855119943619 \tTest acc ID:\t 0.8289150040994807\n",
            "Test loss OOD:\t 1.208124396226862 \tTest acc OOD:\t 0.5070159027128157\n",
            "Epoch 2\n",
            "Train loss:\t 0.35150564208708174\n",
            "Test loss ID:\t 0.5132586041870324 \tTest acc ID:\t 0.8204427439191035\n",
            "Test loss OOD:\t 1.3234887502210981 \tTest acc OOD:\t 0.5182413470533208\n",
            "Epoch 3\n",
            "Train loss:\t 0.28897688191770854\n",
            "Test loss ID:\t 0.5567356593582942 \tTest acc ID:\t 0.8056846132823176\n",
            "Test loss OOD:\t 1.1806016325512354 \tTest acc OOD:\t 0.6024321796071095\n",
            "Epoch 4\n",
            "Train loss:\t 0.23818839270967604\n",
            "Test loss ID:\t 0.647305758005899 \tTest acc ID:\t 0.8002186389723969\n",
            "Test loss OOD:\t 1.6546788645141266 \tTest acc OOD:\t 0.5144995322731525\n",
            "Epoch 5\n",
            "Train loss:\t 0.17530353022026804\n",
            "Test loss ID:\t 0.7132118812073832 \tTest acc ID:\t 0.7917463787920197\n",
            "Test loss OOD:\t 1.831903774948681 \tTest acc OOD:\t 0.5070159027128157\n",
            "Epoch 6\n",
            "Train loss:\t 0.13511332166304843\n",
            "Test loss ID:\t 0.7719511784613132 \tTest acc ID:\t 0.7961191582399563\n",
            "Test loss OOD:\t 1.9163841381669044 \tTest acc OOD:\t 0.5369504209541628\n",
            "Epoch 7\n",
            "Train loss:\t 0.10720419401374183\n",
            "Test loss ID:\t 0.8069708130929781 \tTest acc ID:\t 0.8040448209893414\n",
            "Test loss OOD:\t 2.190377862576176 \tTest acc OOD:\t 0.5042095416276894\n",
            "Epoch 8\n",
            "Train loss:\t 0.08659053166865122\n",
            "Test loss ID:\t 0.928115569508594 \tTest acc ID:\t 0.7786280404482099\n",
            "Test loss OOD:\t 2.093997240943067 \tTest acc OOD:\t 0.5247895229186156\n",
            "Epoch 9\n",
            "Train loss:\t 0.07206655244210664\n",
            "Test loss ID:\t 0.9432020074647406 \tTest acc ID:\t 0.7922929762230118\n",
            "Test loss OOD:\t 2.285680540453862 \tTest acc OOD:\t 0.5378858746492049\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "cg27676g9jtdgc7w4tkt4",
        "execution_id": "67ccb4cc-db4a-455f-9dea-80a9b98cc963",
        "id": "XiECQMBJiffr",
        "outputId": "bd905a8c-3d89-4b9e-c756-f106f8a2dd57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.70it/s]\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.70it/s]\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.70it/s]\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.71it/s]\n",
            "100%|██████████| 915/915 [02:40<00:00,  5.69it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.46it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.47it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.46it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n",
            "100%|██████████| 915/915 [02:47<00:00,  5.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.5827813289041728\n",
            "Test loss ID:\t 0.5069454217734544 \tTest acc ID:\t 0.7972123531019404\n",
            "Test loss OOD:\t 1.258787292329704 \tTest acc OOD:\t 0.41627689429373244\n",
            "Epoch 1\n",
            "Train loss:\t 0.4971626570804523\n",
            "Test loss ID:\t 0.49512369179207344 \tTest acc ID:\t 0.8037715222738453\n",
            "Test loss OOD:\t 1.3088763226919315 \tTest acc OOD:\t 0.40037418147801684\n",
            "Epoch 2\n",
            "Train loss:\t 0.4600279007941647\n",
            "Test loss ID:\t 0.47416845326838286 \tTest acc ID:\t 0.816616561902159\n",
            "Test loss OOD:\t 1.1752765612567173 \tTest acc OOD:\t 0.480823199251637\n",
            "Epoch 3\n",
            "Train loss:\t 0.4327209027901373\n",
            "Test loss ID:\t 0.4808907555497211 \tTest acc ID:\t 0.8122437824542225\n",
            "Test loss OOD:\t 1.215663591728491 \tTest acc OOD:\t 0.47427502338634236\n",
            "Epoch 4\n",
            "Train loss:\t 0.4042392864416206\n",
            "Test loss ID:\t 0.4884067331967146 \tTest acc ID:\t 0.8152500683246788\n",
            "Test loss OOD:\t 1.1503317121635466 \tTest acc OOD:\t 0.49859681945743684\n",
            "Epoch 0\n",
            "Train loss:\t 0.3888397772536903\n",
            "Test loss ID:\t 0.4750152393527653 \tTest acc ID:\t 0.8179830554796392\n",
            "Test loss OOD:\t 1.165178351542529 \tTest acc OOD:\t 0.5014031805425632\n",
            "Epoch 1\n",
            "Train loss:\t 0.3206113873609428\n",
            "Test loss ID:\t 0.5093979571176612 \tTest acc ID:\t 0.8021317299808691\n",
            "Test loss OOD:\t 1.1164133524631752 \tTest acc OOD:\t 0.558465855940131\n",
            "Epoch 2\n",
            "Train loss:\t 0.27025477816376203\n",
            "Test loss ID:\t 0.5685540640483732 \tTest acc ID:\t 0.8111505875922383\n",
            "Test loss OOD:\t 1.3940098285675049 \tTest acc OOD:\t 0.5266604303086997\n",
            "Epoch 3\n",
            "Train loss:\t 0.21973111995297379\n",
            "Test loss ID:\t 0.670914130722699 \tTest acc ID:\t 0.8037715222738453\n",
            "Test loss OOD:\t 1.6972184216274935 \tTest acc OOD:\t 0.5070159027128157\n",
            "Epoch 4\n",
            "Train loss:\t 0.1773304806900073\n",
            "Test loss ID:\t 0.7000853559083264 \tTest acc ID:\t 0.7993987428259087\n",
            "Test loss OOD:\t 1.7745348732261097 \tTest acc OOD:\t 0.5023386342376053\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=3)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "freeze_embeddings(model)\n",
        "\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 5)\n",
        "\n",
        "unfreeze_embeddings(model)\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "vks2p5xst797rn6lnc9k4g",
        "id": "I2XWGXOWiffs",
        "outputId": "530002cf-2e70-45ad-8a85-2929d1c466f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 915/915 [02:44<00:00,  5.57it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.43it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n",
            "100%|██████████| 915/915 [02:48<00:00,  5.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss:\t 0.14255614224719546\n",
            "Test loss ID:\t 0.7466898287444012 \tTest acc ID:\t 0.7944793659469801\n",
            "Test loss OOD:\t 1.9736767263316057 \tTest acc OOD:\t 0.5023386342376053\n",
            "Epoch 1\n",
            "Train loss:\t 0.12120253589828728\n",
            "Test loss ID:\t 0.8213532206480918 \tTest acc ID:\t 0.8040448209893414\n",
            "Test loss OOD:\t 2.0777307733729042 \tTest acc OOD:\t 0.5304022450888681\n",
            "Epoch 2\n",
            "Train loss:\t 0.08344256124367602\n",
            "Test loss ID:\t 0.8870184972234394 \tTest acc ID:\t 0.7952992620934681\n",
            "Test loss OOD:\t 2.003106558585868 \tTest acc OOD:\t 0.5603367633302152\n",
            "Epoch 3\n",
            "Train loss:\t 0.07381773127619523\n",
            "Test loss ID:\t 0.8799423997816832 \tTest acc ID:\t 0.7813610276031703\n",
            "Test loss OOD:\t 2.1186257493408287 \tTest acc OOD:\t 0.5154349859681946\n",
            "Epoch 4\n",
            "Train loss:\t 0.06188736435667169\n",
            "Test loss ID:\t 0.970144082751611 \tTest acc ID:\t 0.7862804044820989\n",
            "Test loss OOD:\t 2.032825766459984 \tTest acc OOD:\t 0.5743685687558466\n"
          ]
        }
      ],
      "source": [
        "#!g1.1\n",
        "train_epochs(model, train_loader, str_loader, nstr_loader, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "w0fixanprlahysn2jyimw8",
        "id": "-lHeZPu8iffs"
      },
      "source": [
        "# \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "notebookId": "4cdabe51-446e-44b2-a3af-58c7040183b3",
    "notebookPath": "finetunning.ipynb",
    "vscode": {
      "interpreter": {
        "hash": "24f792973ec11b47f8dd64a83177ed346d5171e3aa1ef0ed31974f0bdbc6a08a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cd415b301bc4b7eab8abb91a09753fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3227260387c64e2792cb56b9528c83cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a200f2775b46bf8c1b093263368b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2dbcd68188c47d898b0d11a168eb59e",
            "placeholder": "​",
            "style": "IPY_MODEL_6c3b02c739934535ac7e3bb895cf941f",
            "value": " 2/2 [00:00&lt;00:00, 76.63it/s]"
          }
        },
        "6c3b02c739934535ac7e3bb895cf941f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d733c5fa15c47b5adc833a08ffe38be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5fee55daf514a52bf5d7be48cadf26d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb110f7b2ecb4d64bb8c983acce11c9f",
            "value": 2
          }
        },
        "9b58fbdb6f7b43eebbc1c7ccf6a5fdf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67844316fdd4d04a27196dcb2fac506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7c0fa59de874b209d69a32fca9ad1d1",
              "IPY_MODEL_7d733c5fa15c47b5adc833a08ffe38be",
              "IPY_MODEL_69a200f2775b46bf8c1b093263368b02"
            ],
            "layout": "IPY_MODEL_3227260387c64e2792cb56b9528c83cf"
          }
        },
        "d7c0fa59de874b209d69a32fca9ad1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd415b301bc4b7eab8abb91a09753fa",
            "placeholder": "​",
            "style": "IPY_MODEL_9b58fbdb6f7b43eebbc1c7ccf6a5fdf4",
            "value": "100%"
          }
        },
        "e2dbcd68188c47d898b0d11a168eb59e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5fee55daf514a52bf5d7be48cadf26d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb110f7b2ecb4d64bb8c983acce11c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}