{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqdnYxZFNrKw",
        "outputId": "75473d77-03ec-4f21-80f5-50e12777b2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (0.29.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi) (7.1.2)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb==1.3.1\n",
            "  Downloading ogb-1.3.1-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 KB\u001b[0m \u001b[31m805.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.15.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.1) (1.24.3)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb==1.3.1) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb==1.3.1) (2.25.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.1) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.1) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->ogb==1.3.1) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->ogb==1.3.1) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb==1.3.1) (4.0.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7047 sha256=f53c9817a2cb16f006af5fa346803382b4130d46b926b6427b74837ae2f2fc27\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.1 outdated-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.3.1\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas==1.2.0\n",
            "  Downloading pandas-1.2.0-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from pandas==1.2.0) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.2.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.0) (1.15.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp38-cp38-linux_x86_64.whl size=44634 sha256=02416ca22210cc3d20e19ff17f3d1dfca08df366bf612ca27310528599c20ab3\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/90/db/290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, pandas\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.2.0 pyyaml-5.3.1\n"
          ]
        }
      ],
      "source": [
        "%pip install rdkit-pypi cython\n",
        "%pip install torch torchvision torchaudio \n",
        "%pip install ogb==1.3.1 tqdm\n",
        "%pip install pyyaml==5.3.1 pandas==1.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com//TienjinHuang/UGTs-LoG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8wGxoNrSYag",
        "outputId": "8fe1aef8-428d-47a8-c41a-d289bfaa4dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UGTs-LoG'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 195 (delta 39), reused 145 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (195/195), 23.68 MiB | 7.15 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "vtcZgvpSSh6I",
        "outputId": "96c9f9e4-5818-4679-9c15-ada6cee43850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch_geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=e319a425534c4798e39f8f318b333d9286e10cd4cd9f8b13e6472ce1a63a3e13\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: psutil, torch_geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch_geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch_sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kmkt5RUStW4",
        "outputId": "dfdb8824-c7cf-484a-9923-068a4022dd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch_sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch_sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch_sparse\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 361, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 348, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 222, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/wheel_builder.py\", line 269, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 221, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 205, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1434, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.8/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1187, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 110, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 676, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 626, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 103, in print_exception\n",
            "    for line in TracebackException(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 508, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 366, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.8/traceback.py\", line 288, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.8/linecache.py\", line 137, in updatecache\n",
            "    lines = fp.readlines()\n",
            "  File \"/usr/lib/python3.8/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_zk9M_kUB-V",
        "outputId": "7b9f6b11-a14f-4181-e46b-3c29722ca418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch-geometric 2.2.0\n",
            "Uninstalling torch-geometric-2.2.0:\n",
            "  Successfully uninstalled torch-geometric-2.2.0\n",
            "\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.21.6)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-ly9_ehq9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-ly9_ehq9\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 9e2c604495bdcd7c56c4104ac9900f6d3c98eb66\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (4.64.1)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (2.25.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (5.9.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.7.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric==2.3.0) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric==2.3.0) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric==2.3.0) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics->torch-geometric==2.3.0) (1.13.1+cu116)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=858555 sha256=ee754e64bf6b47142b1ccca6a3867919e4f00d04b2dc47b05cb9086e26329a0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ahsn73_x/wheels/ba/e1/8e/28297c3201c884d3ea8c47ba71a9e71e547e556c0caa9cf5a2\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torchmetrics, torch-geometric\n",
            "Successfully installed torch-geometric-2.3.0 torchmetrics-0.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dgl -f https://data.dgl.ai/wheels/cu116/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8LyZiyhUUWS",
        "outputId": "9f39724a-3d01-449d-e9a4-426817bf11eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu116/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu116/dgl-1.0.0%2Bcu116-cp38-cp38-manylinux1_x86_64.whl (265.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.8/265.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.0.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall dgl dgl-cu111 -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LpVQ-bVWLdJ",
        "outputId": "f434db0a-11eb-4a20-f8cf-17366cf0bbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dgl 1.0.0+cu116\n",
            "Uninstalling dgl-1.0.0+cu116:\n",
            "  Successfully uninstalled dgl-1.0.0+cu116\n",
            "\u001b[33mWARNING: Skipping dgl-cu111 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dgl==0.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROHgHutFcQ7Y",
        "outputId": "6322c15c-4d8b-420f-b7c2-5383806590ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl==0.6.1\n",
            "  Downloading dgl-0.6.1-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl==0.6.1) (1.7.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl==0.6.1) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl==0.6.1) (3.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl==0.6.1) (1.21.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl==0.6.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl==0.6.1) (4.0.0)\n",
            "Installing collected packages: dgl\n",
            "  Attempting uninstall: dgl\n",
            "    Found existing installation: dgl 1.0.0+cu116\n",
            "    Uninstalling dgl-1.0.0+cu116:\n",
            "      Successfully uninstalled dgl-1.0.0+cu116\n",
            "Successfully installed dgl-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install littleballoffur==1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUJX4FjDckHf",
        "outputId": "aa042666-2da7-46d4-a05d-30d89cbbcc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting littleballoffur==1.0.0\n",
            "  Downloading littleballoffur-1.0.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (4.64.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (0.16)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from littleballoffur==1.0.0) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->littleballoffur==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->littleballoffur==1.0.0) (2022.7.1)\n",
            "Building wheels for collected packages: littleballoffur\n",
            "  Building wheel for littleballoffur (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleballoffur: filename=littleballoffur-1.0.0-py3-none-any.whl size=25710 sha256=cce69141614562766d25b509b6014be3440ca9e840b4054d00ac1608ab800563\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/2b/e9/bb81de03ea2c4e5e7917f84a2c261f8a41a388615064e649f9\n",
            "Successfully built littleballoffur\n",
            "Installing collected packages: littleballoffur\n",
            "Successfully installed littleballoffur-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset Cora --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idVjNydCNvj0",
        "outputId": "4a38e23b-a0e2-4c48-c559-5a6ea03d4bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Namespace(activation='relu', attack=None, attack_eps=0, auroc=False, bn_affine=False, bn_momentum=0.1, bn_track_running_stats=True, checkpoint_epochs=[], command='train', cuda=True, dataset='Cora', dim_hidden=256, dropout=0.0, epochs=400, exp_name='test10', finetuning_epochs=0, finetuning_lr=None, force_restart=False, heads=1, init_mode='kaiming_uniform', init_mode_linear=None, init_mode_mask='kaiming_uniform', init_scale=1.0, init_scale_score=1.0, learning_framework='SupervisedLearning', linear_sparsity=0.95, lr=0.01, lr_milestones=[900, 1000, 1100], lr_scheduler='MultiStepLR', multisteplr_gamma=0.1, num_classes=7, num_feats=1433, num_gpus=1, num_layers=2, optimizer='Adam', output_dir='__outputs__', print_train_loss=False, random_seed=100, repeat_times=1, resume=False, sampling=None, samplingtype=None, save_best_model=True, seed_by_time=True, sparse_decay=True, sync_dir='__sync__', train_mode='score_only', transductive=True, type_model='GAT', type_norm='None', warm_epochs=0, weight_decay=0.0, weight_l1=0.0)\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 18342 / 366848 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 89 / 1792 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 0 / 7 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 0 / 7 (sparsity = 0.95 )\n",
            "Params after/before pruned:\t 18461 / 369166 (sparsity: 0.9499926862170406)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.741 ece 0.0\n",
            "acc mean: 0.741  acc std: 0.0 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset Citeseer --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwz13qlrgYho",
        "outputId": "9a5fb654-6132-42c3-f807-38531fc5f392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Namespace(activation='relu', attack=None, attack_eps=0, auroc=False, bn_affine=False, bn_momentum=0.1, bn_track_running_stats=True, checkpoint_epochs=[], command='train', cuda=True, dataset='Citeseer', dim_hidden=256, dropout=0.0, epochs=400, exp_name='test10', finetuning_epochs=0, finetuning_lr=None, force_restart=False, heads=1, init_mode='kaiming_uniform', init_mode_linear=None, init_mode_mask='kaiming_uniform', init_scale=1.0, init_scale_score=1.0, learning_framework='SupervisedLearning', linear_sparsity=0.95, lr=0.01, lr_milestones=[900, 1000, 1100], lr_scheduler='MultiStepLR', multisteplr_gamma=0.1, num_classes=6, num_feats=3703, num_gpus=1, num_layers=2, optimizer='Adam', output_dir='__outputs__', print_train_loss=False, random_seed=100, repeat_times=1, resume=False, sampling=None, samplingtype=None, save_best_model=True, seed_by_time=True, sparse_decay=True, sync_dir='__sync__', train_mode='score_only', transductive=True, type_model='GAT', type_norm='None', warm_epochs=0, weight_decay=0.0, weight_l1=0.0)\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 947968\n",
            "module.layers_GCN.0.lin_src.weight_score: 47398 / 947968 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.lin_src.weight: 1536\n",
            "module.layers_GCN.1.lin_src.weight_score: 76 / 1536 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_src.weight: 6\n",
            "module.layers_GCN.1.att_src.weight_score: 0 / 6 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_dst.weight: 6\n",
            "module.layers_GCN.1.att_dst.weight_score: 0 / 6 (sparsity = 0.95 )\n",
            "Params after/before pruned:\t 47504 / 950028 (sparsity: 0.9499972632385572)\n",
            "Total Params:\t 1900056\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.701 ece 0.0\n",
            "acc mean: 0.701  acc std: 0.0 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset Pubmed --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvJkKj0Ggv7d",
        "outputId": "6eeaffce-2266-4467-8f54-2664eb5f1d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Namespace(activation='relu', attack=None, attack_eps=0, auroc=False, bn_affine=False, bn_momentum=0.1, bn_track_running_stats=True, checkpoint_epochs=[], command='train', cuda=True, dataset='Pubmed', dim_hidden=256, dropout=0.0, epochs=400, exp_name='test10', finetuning_epochs=0, finetuning_lr=None, force_restart=False, heads=1, init_mode='kaiming_uniform', init_mode_linear=None, init_mode_mask='kaiming_uniform', init_scale=1.0, init_scale_score=1.0, learning_framework='SupervisedLearning', linear_sparsity=0.95, lr=0.01, lr_milestones=[900, 1000, 1100], lr_scheduler='MultiStepLR', multisteplr_gamma=0.1, num_classes=3, num_feats=500, num_gpus=1, num_layers=2, optimizer='Adam', output_dir='__outputs__', print_train_loss=False, random_seed=100, repeat_times=1, resume=False, sampling=None, samplingtype=None, save_best_model=True, seed_by_time=True, sparse_decay=True, sync_dir='__sync__', train_mode='score_only', transductive=True, type_model='GAT', type_norm='None', warm_epochs=0, weight_decay=0.0, weight_l1=0.0)\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 128000\n",
            "module.layers_GCN.0.lin_src.weight_score: 6400 / 128000 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.lin_src.weight: 768\n",
            "module.layers_GCN.1.lin_src.weight_score: 38 / 768 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_src.weight: 3\n",
            "module.layers_GCN.1.att_src.weight_score: 0 / 3 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_dst.weight: 3\n",
            "module.layers_GCN.1.att_dst.weight_score: 0 / 3 (sparsity = 0.95 )\n",
            "Params after/before pruned:\t 6467 / 129286 (sparsity: 0.9499791160682518)\n",
            "Total Params:\t 258572\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.78 ece 0.0\n",
            "acc mean: 0.78  acc std: 0.0 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset ogbn-arxiv --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rq3sOrVhBfJ",
        "outputId": "bb626da7-0656-456d-d214-bf3b029e8ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Namespace(activation='relu', attack=None, attack_eps=0, auroc=False, bn_affine=False, bn_momentum=0.1, bn_track_running_stats=True, checkpoint_epochs=[], command='train', cuda=True, dataset='ogbn-arxiv', dim_hidden=256, dropout=0.0, epochs=400, exp_name='test10', finetuning_epochs=0, finetuning_lr=None, force_restart=False, heads=1, init_mode='kaiming_uniform', init_mode_linear=None, init_mode_mask='kaiming_uniform', init_scale=1.0, init_scale_score=1.0, learning_framework='SupervisedLearning', linear_sparsity=0.95, lr=0.01, lr_milestones=[900, 1000, 1100], lr_scheduler='MultiStepLR', multisteplr_gamma=0.1, num_classes=40, num_feats=128, num_gpus=1, num_layers=2, optimizer='Adam', output_dir='__outputs__', print_train_loss=False, random_seed=100, repeat_times=1, resume=False, sampling=None, samplingtype=None, save_best_model=True, seed_by_time=True, sparse_decay=True, sync_dir='__sync__', train_mode='score_only', transductive=True, type_model='GAT', type_norm='None', warm_epochs=0, weight_decay=0.0, weight_l1=0.0)\n",
            "Number of available gpus:  1\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n",
            "Downloaded 0.08 GB: 100% 81/81 [00:08<00:00,  9.43it/s]\n",
            "Extracting dataset/arxiv.zip\n",
            "Processing...\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n",
            "100% 1/1 [00:00<00:00, 16912.52it/s]\n",
            "Converting graphs into PyG objects...\n",
            "100% 1/1 [00:00<00:00, 4559.03it/s]\n",
            "Saving...\n",
            "Done!\n",
            "module.layers_GCN.0.lin_src.weight: 32768\n",
            "module.layers_GCN.0.lin_src.weight_score: 1638 / 32768 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 12 / 256 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.lin_src.weight: 10240\n",
            "module.layers_GCN.1.lin_src.weight_score: 512 / 10240 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_src.weight: 40\n",
            "module.layers_GCN.1.att_src.weight_score: 2 / 40 (sparsity = 0.95 )\n",
            "module.layers_GCN.1.att_dst.weight: 40\n",
            "module.layers_GCN.1.att_dst.weight_score: 2 / 40 (sparsity = 0.95 )\n",
            "Params after/before pruned:\t 2181 / 43600 (sparsity: 0.9499770642201835)\n",
            "Total Params:\t 87200\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.43118737526490136 ece 0.0\n",
            "acc mean: 0.43118737526490136  acc std: 0.0 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ugts/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset Cora --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hnQs2_V8Yn6",
        "outputId": "bfdd8698-d5a2-44a0-f2d7-3ab6aa8b1d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 348505 / 366848 (sparsity = 0.05 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 243 / 256 (sparsity = 0.05 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 243 / 256 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1702 / 1792 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.05 )\n",
            "Params after/before pruned:\t 350711 / 369166 (sparsity: 0.0499910609319385)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.731 ece 0.0\n",
            "0.731Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 330163 / 366848 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1612 / 1792 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "Params after/before pruned:\t 332253 / 369166 (sparsity: 0.0999902482893874)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.812 ece 0.0\n",
            "0.812Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 311820 / 366848 (sparsity = 0.15000000000000002 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 217 / 256 (sparsity = 0.15000000000000002 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 217 / 256 (sparsity = 0.15000000000000002 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1523 / 1792 (sparsity = 0.15000000000000002 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 5 / 7 (sparsity = 0.15000000000000002 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 5 / 7 (sparsity = 0.15000000000000002 )\n",
            "Params after/before pruned:\t 313793 / 369166 (sparsity: 0.14999485326384332)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.808 ece 0.0\n",
            "0.808Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 293478 / 366848 (sparsity = 0.2 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 204 / 256 (sparsity = 0.2 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 204 / 256 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1433 / 1792 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 5 / 7 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 5 / 7 (sparsity = 0.2 )\n",
            "Params after/before pruned:\t 295335 / 369166 (sparsity: 0.19999404062129233)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.814 ece 0.0\n",
            "0.814Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 275136 / 366848 (sparsity = 0.25 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 192 / 256 (sparsity = 0.25 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 192 / 256 (sparsity = 0.25 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1344 / 1792 (sparsity = 0.25 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 5 / 7 (sparsity = 0.25 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 5 / 7 (sparsity = 0.25 )\n",
            "Params after/before pruned:\t 276876 / 369166 (sparsity: 0.24999593678724474)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.814 ece 0.0\n",
            "0.814Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 256793 / 366848 (sparsity = 0.30000000000000004 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 179 / 256 (sparsity = 0.30000000000000004 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 179 / 256 (sparsity = 0.30000000000000004 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1254 / 1792 (sparsity = 0.30000000000000004 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 4 / 7 (sparsity = 0.30000000000000004 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 4 / 7 (sparsity = 0.30000000000000004 )\n",
            "Params after/before pruned:\t 258419 / 369166 (sparsity: 0.29999241533619025)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.818 ece 0.0\n",
            "0.818Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 238451 / 366848 (sparsity = 0.35000000000000003 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 166 / 256 (sparsity = 0.35000000000000003 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 166 / 256 (sparsity = 0.35000000000000003 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1164 / 1792 (sparsity = 0.35000000000000003 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 4 / 7 (sparsity = 0.35000000000000003 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 4 / 7 (sparsity = 0.35000000000000003 )\n",
            "Params after/before pruned:\t 239961 / 369166 (sparsity: 0.34999160269363916)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.809 ece 0.0\n",
            "0.809Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 220108 / 366848 (sparsity = 0.4 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 153 / 256 (sparsity = 0.4 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 153 / 256 (sparsity = 0.4 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1075 / 1792 (sparsity = 0.4 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 4 / 7 (sparsity = 0.4 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 4 / 7 (sparsity = 0.4 )\n",
            "Params after/before pruned:\t 221503 / 369166 (sparsity: 0.3999907900510882)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.818 ece 0.0\n",
            "0.818Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 201766 / 366848 (sparsity = 0.45 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 140 / 256 (sparsity = 0.45 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 140 / 256 (sparsity = 0.45 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 985 / 1792 (sparsity = 0.45 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 3 / 7 (sparsity = 0.45 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 3 / 7 (sparsity = 0.45 )\n",
            "Params after/before pruned:\t 203043 / 369166 (sparsity: 0.4499953950255441)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.815 ece 0.0\n",
            "0.815Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 183424 / 366848 (sparsity = 0.5 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 128 / 256 (sparsity = 0.5 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 128 / 256 (sparsity = 0.5 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 896 / 1792 (sparsity = 0.5 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 3 / 7 (sparsity = 0.5 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 3 / 7 (sparsity = 0.5 )\n",
            "Params after/before pruned:\t 184584 / 369166 (sparsity: 0.4999972911914965)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.807 ece 0.0\n",
            "0.807Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 165081 / 366848 (sparsity = 0.55 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 115 / 256 (sparsity = 0.55 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 115 / 256 (sparsity = 0.55 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 806 / 1792 (sparsity = 0.55 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 3 / 7 (sparsity = 0.55 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 3 / 7 (sparsity = 0.55 )\n",
            "Params after/before pruned:\t 166129 / 369166 (sparsity: 0.549988352123435)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.807 ece 0.0\n",
            "0.807Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 146739 / 366848 (sparsity = 0.6000000000000001 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 102 / 256 (sparsity = 0.6000000000000001 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 102 / 256 (sparsity = 0.6000000000000001 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 716 / 1792 (sparsity = 0.6000000000000001 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 2 / 7 (sparsity = 0.6000000000000001 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 2 / 7 (sparsity = 0.6000000000000001 )\n",
            "Params after/before pruned:\t 147669 / 369166 (sparsity: 0.5999929570978909)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.807 ece 0.0\n",
            "0.807Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 128396 / 366848 (sparsity = 0.65 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 89 / 256 (sparsity = 0.65 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 89 / 256 (sparsity = 0.65 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 627 / 1792 (sparsity = 0.65 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 2 / 7 (sparsity = 0.65 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 2 / 7 (sparsity = 0.65 )\n",
            "Params after/before pruned:\t 129211 / 369166 (sparsity: 0.6499921444553398)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.803 ece 0.0\n",
            "0.803Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 110054 / 366848 (sparsity = 0.7000000000000001 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 76 / 256 (sparsity = 0.7000000000000001 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 76 / 256 (sparsity = 0.7000000000000001 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 537 / 1792 (sparsity = 0.7000000000000001 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 2 / 7 (sparsity = 0.7000000000000001 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 2 / 7 (sparsity = 0.7000000000000001 )\n",
            "Params after/before pruned:\t 110753 / 369166 (sparsity: 0.6999913318127888)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.807 ece 0.0\n",
            "0.807Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 91712 / 366848 (sparsity = 0.75 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 64 / 256 (sparsity = 0.75 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 64 / 256 (sparsity = 0.75 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 448 / 1792 (sparsity = 0.75 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 1 / 7 (sparsity = 0.75 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 1 / 7 (sparsity = 0.75 )\n",
            "Params after/before pruned:\t 92292 / 369166 (sparsity: 0.7499986455957482)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.799 ece 0.0\n",
            "0.799Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 73369 / 366848 (sparsity = 0.8 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 51 / 256 (sparsity = 0.8 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 51 / 256 (sparsity = 0.8 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 358 / 1792 (sparsity = 0.8 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 1 / 7 (sparsity = 0.8 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 1 / 7 (sparsity = 0.8 )\n",
            "Params after/before pruned:\t 73837 / 369166 (sparsity: 0.7999897065276868)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.796 ece 0.0\n",
            "0.796Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 55027 / 366848 (sparsity = 0.8500000000000001 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 38 / 256 (sparsity = 0.8500000000000001 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 38 / 256 (sparsity = 0.8500000000000001 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 268 / 1792 (sparsity = 0.8500000000000001 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 1 / 7 (sparsity = 0.8500000000000001 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 1 / 7 (sparsity = 0.8500000000000001 )\n",
            "Params after/before pruned:\t 55379 / 369166 (sparsity: 0.8499888938851357)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.796 ece 0.0\n",
            "0.796Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 36684 / 366848 (sparsity = 0.9 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 25 / 256 (sparsity = 0.9 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 25 / 256 (sparsity = 0.9 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 179 / 1792 (sparsity = 0.9 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 0 / 7 (sparsity = 0.9 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 0 / 7 (sparsity = 0.9 )\n",
            "Params after/before pruned:\t 36919 / 369166 (sparsity: 0.8999934988595917)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.776 ece 0.0\n",
            "0.776Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 18342 / 366848 (sparsity = 0.9500000000000001 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 12 / 256 (sparsity = 0.9500000000000001 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 12 / 256 (sparsity = 0.9500000000000001 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 89 / 1792 (sparsity = 0.9500000000000001 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 0 / 7 (sparsity = 0.9500000000000001 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 0 / 7 (sparsity = 0.9500000000000001 )\n",
            "Params after/before pruned:\t 18461 / 369166 (sparsity: 0.9499926862170406)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.741 ece 0.0\n",
            "0.7410.731\n",
            "acc mean: 0.7988421052631578  acc std: 0.023602549277778707 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results = [0.731, 0.812, 0.808, 0.814, 0.814, 0.818, 0.809, 0.818, 0.815, 0.807, 0.807, 0.807, 0.803, 0.807, 0.799, 0.796, 0.796, 0.776, 0.741]\n",
        "xs = [0.05 * i for i in range(1, 20)]\n",
        "\n",
        "plt.plot(xs, results)\n",
        "plt.xlabel('Sparcity')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "F-mTVhJw-I8F",
        "outputId": "c382373b-ce55-426f-ddfd-5c61a903fc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ugts/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset Cora --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFE_VLlx__GH",
        "outputId": "078e7920-5dbe-4e99-8222-b3b471ee1000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 363179 / 366848 (sparsity = 0.01 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 253 / 256 (sparsity = 0.01 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 253 / 256 (sparsity = 0.01 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1774 / 1792 (sparsity = 0.01 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.01 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.01 )\n",
            "Params after/before pruned:\t 365477 / 369166 (sparsity: 0.009992794569380736)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.48 ece 0.0\n",
            "0.48Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 359511 / 366848 (sparsity = 0.02 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 250 / 256 (sparsity = 0.02 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 250 / 256 (sparsity = 0.02 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1756 / 1792 (sparsity = 0.02 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.02 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.02 )\n",
            "Params after/before pruned:\t 361785 / 369166 (sparsity: 0.019993715564271874)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.66 ece 0.0\n",
            "0.66Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 355842 / 366848 (sparsity = 0.03 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 248 / 256 (sparsity = 0.03 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 248 / 256 (sparsity = 0.03 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1738 / 1792 (sparsity = 0.03 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.03 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.03 )\n",
            "Params after/before pruned:\t 358094 / 369166 (sparsity: 0.02999192775065962)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.704 ece 0.0\n",
            "0.704Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 352174 / 366848 (sparsity = 0.04 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 245 / 256 (sparsity = 0.04 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 245 / 256 (sparsity = 0.04 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1720 / 1792 (sparsity = 0.04 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.04 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.04 )\n",
            "Params after/before pruned:\t 354402 / 369166 (sparsity: 0.03999284874555076)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.708 ece 0.0\n",
            "0.708Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 348505 / 366848 (sparsity = 0.05 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 243 / 256 (sparsity = 0.05 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 243 / 256 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1702 / 1792 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.05 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.05 )\n",
            "Params after/before pruned:\t 350711 / 369166 (sparsity: 0.0499910609319385)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.737 ece 0.0\n",
            "0.737Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 344837 / 366848 (sparsity = 0.06 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 240 / 256 (sparsity = 0.06 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 240 / 256 (sparsity = 0.06 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1684 / 1792 (sparsity = 0.06 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.06 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.06 )\n",
            "Params after/before pruned:\t 347019 / 369166 (sparsity: 0.05999198192682964)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.769 ece 0.0\n",
            "0.769Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 341168 / 366848 (sparsity = 0.07 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 238 / 256 (sparsity = 0.07 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 238 / 256 (sparsity = 0.07 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1666 / 1792 (sparsity = 0.07 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.07 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.07 )\n",
            "Params after/before pruned:\t 343328 / 369166 (sparsity: 0.06999019411321739)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.794 ece 0.0\n",
            "0.794Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 337500 / 366848 (sparsity = 0.08 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 235 / 256 (sparsity = 0.08 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 235 / 256 (sparsity = 0.08 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1648 / 1792 (sparsity = 0.08 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.08 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.08 )\n",
            "Params after/before pruned:\t 339636 / 369166 (sparsity: 0.07999111510810852)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.807 ece 0.0\n",
            "0.807Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 333831 / 366848 (sparsity = 0.09 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 232 / 256 (sparsity = 0.09 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 232 / 256 (sparsity = 0.09 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1630 / 1792 (sparsity = 0.09 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.09 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.09 )\n",
            "Params after/before pruned:\t 335943 / 369166 (sparsity: 0.08999474491150328)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.814 ece 0.0\n",
            "0.814Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 330163 / 366848 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1612 / 1792 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "Params after/before pruned:\t 332253 / 369166 (sparsity: 0.0999902482893874)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "best acc: 0.814 ece 0.0\n",
            "0.8140.48\n",
            "acc mean: 0.7287000000000001  acc std: 0.0970824906973446 ece mean: 0.0 ece std 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results = [0.48, 0.66, 0.704, 0.708, 0.737, 0.769, 0.794, 0.807, 0.814, 0.814]\n",
        "xs = [0.01 * (i + 1) for i in range(10)]\n",
        "\n",
        "plt.plot(xs, results)\n",
        "plt.xlabel('Sparcity')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Yo8Qq7aAA94x",
        "outputId": "159ff0b9-f0f9-4fa2-dde1-59077f166c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset WISCONSIN --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWVnNvwyhK-Q",
        "outputId": "0168a11e-7636-4cb1-bbb6-7feea2074a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Namespace(activation='relu', attack=None, attack_eps=0, auroc=False, bn_affine=False, bn_momentum=0.1, bn_track_running_stats=True, checkpoint_epochs=[], command='train', cuda=True, dataset='WISCONSIN', dim_hidden=256, dropout=0.0, epochs=400, exp_name='test10', finetuning_epochs=0, finetuning_lr=None, force_restart=False, heads=1, init_mode='kaiming_uniform', init_mode_linear=None, init_mode_mask='kaiming_uniform', init_scale=1.0, init_scale_score=1.0, learning_framework='SupervisedLearning', linear_sparsity=0.95, lr=0.01, lr_milestones=[900, 1000, 1100], lr_scheduler='MultiStepLR', multisteplr_gamma=0.1, num_gpus=1, num_layers=2, optimizer='Adam', output_dir='__outputs__', print_train_loss=False, random_seed=100, repeat_times=1, resume=False, sampling=None, samplingtype=None, save_best_model=True, seed_by_time=True, sparse_decay=True, sync_dir='__sync__', train_mode='score_only', transductive=True, type_model='GAT', type_norm='None', warm_epochs=0, weight_decay=0.0, weight_l1=0.0)\n",
            "Number of available gpus:  1\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/wisconsin/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/wisconsin_split_0.6_0.2_9.npz\n",
            "Processing...\n",
            "Done!\n",
            "Traceback (most recent call last):\n",
            "  File \"UGTs-LoG/main.py\", line 56, in <module>\n",
            "    main(args)\n",
            "  File \"UGTs-LoG/main.py\", line 34, in main\n",
            "    acc,ece=command(args.exp_name, args=args,idx=i)\n",
            "  File \"/content/UGTs-LoG/commands/train.py\", line 65, in train\n",
            "    learner = SupervisedLearning(outman, args, device)\n",
            "  File \"/content/UGTs-LoG/models/supervised_learning.py\", line 103, in __init__\n",
            "    self.data=load_data(self.args.dataset,self.args.random_seed,self.args.attack,self.args.attack_eps)\n",
            "  File \"/content/UGTs-LoG/models/Dataloader.py\", line 149, in load_data\n",
            "    data = change_split(data, dataset, which_split=int(which_run // 10))\n",
            "  File \"/content/UGTs-LoG/models/Dataloader.py\", line 120, in change_split\n",
            "    data = manual_split_WebKB_Actor(data, which_split)\n",
            "  File \"/content/UGTs-LoG/models/Dataloader.py\", line 106, in manual_split_WebKB_Actor\n",
            "    assert which_split in np.arange(10, dtype=int).tolist()\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls UGTs-LoG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BpjNecytn2Z",
        "outputId": "d0dca392-65bb-48fc-b655-cc008f6d74f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_sparsity1.pdf  commands\t   models\tREADME.md\n",
            "all_sparsity.png   Examples.ipynb  __outputs__\tutils\n",
            "base_options.py    main.py\t   __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ugts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh4rnws1tqw4",
        "outputId": "0a5d1e18-b670-4f13-f289-d00f0fdb8144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_sparsity1.pdf  commands\t   models\tREADME.md\n",
            "all_sparsity.png   Examples.ipynb  __outputs__\tutils\n",
            "base_options.py    main.py\t   __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dict2obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qtiDgbvwFoC",
        "outputId": "d9a208c1-940c-4437-f431-0bb587ca92c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dict2obj\n",
            "  Downloading dict2obj-1.2.0.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: dict2obj\n",
            "  Building wheel for dict2obj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dict2obj: filename=dict2obj-1.2.0-py3-none-any.whl size=2931 sha256=0072551d0c0254fb1d797224302425ee9186a2f54919dc5a1b85f41feb30b0ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/f6/68/5a48f1628681fdd0cbc6889eb4abd6db064156f29db810267c\n",
            "Successfully built dict2obj\n",
            "Installing collected packages: dict2obj\n",
            "Successfully installed dict2obj-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mode=score_only\n",
        "#hidden=384\n",
        "dataset=Cora\n",
        "for hidden in 256\n",
        "do\n",
        "\tfor depth in 2\n",
        "\tdo\n",
        "\t    for model in GAT\n",
        "\t    do\n",
        "\t        for S in 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n",
        "\t        do\n",
        "          #!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset WISCONSIN --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100\n",
        "\t        python ugts/main.py --command train  --num_layers $depth --dim_hidden 256 --dataset $dataset --heads 1  --train_mode $mode --linear_sparsity $S --exp_name test10 --epochs 400  --type_model $model  --weight_l1 0  --repeat_times 1 --sparse_decay --lr 0.01 --weight_decay 0\n",
        "\t        done\n",
        "\t    done\n",
        "\tdone\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dPMgLNcltkFK",
        "outputId": "36ccbb3f-a430-4924-87e7-6765c36bb850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Number of available gpus:  1\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 330163 / 366848 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 230 / 256 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1612 / 1792 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 6 / 7 (sparsity = 0.1 )\n",
            "Params after/before pruned:\t 332253 / 369166 (sparsity: 0.0999902482893874)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.815 ece 0.0\n",
            "0.815\n",
            "Traceback (most recent call last):\n",
            "  File \"ugts/main.py\", line 58, in <module>\n",
            "    main(args)\n",
            "  File \"ugts/main.py\", line 38, in main\n",
            "    results_acc.append()\n",
            "TypeError: append() takes exactly one argument (0 given)\n",
            "Using backend: pytorch\n",
            "Number of available gpus:  1\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "module.layers_GCN.0.lin_src.weight: 366848\n",
            "module.layers_GCN.0.lin_src.weight_score: 293478 / 366848 (sparsity = 0.2 )\n",
            "module.layers_GCN.0.att_src.weight: 256\n",
            "module.layers_GCN.0.att_src.weight_score: 204 / 256 (sparsity = 0.2 )\n",
            "module.layers_GCN.0.att_dst.weight: 256\n",
            "module.layers_GCN.0.att_dst.weight_score: 204 / 256 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.lin_src.weight: 1792\n",
            "module.layers_GCN.1.lin_src.weight_score: 1433 / 1792 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.att_src.weight: 7\n",
            "module.layers_GCN.1.att_src.weight_score: 5 / 7 (sparsity = 0.2 )\n",
            "module.layers_GCN.1.att_dst.weight: 7\n",
            "module.layers_GCN.1.att_dst.weight_score: 5 / 7 (sparsity = 0.2 )\n",
            "Params after/before pruned:\t 295335 / 369166 (sparsity: 0.19999404062129233)\n",
            "Total Params:\t 738332\n",
            "/content/__outputs__/test10/dump..test10.pth\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "best acc: 0.817 ece 0.0\n",
            "0.817\n",
            "Traceback (most recent call last):\n",
            "  File \"ugts/main.py\", line 58, in <module>\n",
            "    main(args)\n",
            "  File \"ugts/main.py\", line 38, in main\n",
            "    results_acc.append()\n",
            "TypeError: append() takes exactly one argument (0 given)\n",
            "Using backend: pytorch\n",
            "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.5.\n",
            "Number of available gpus:  1\n",
            "Traceback (most recent call last):\n",
            "  File \"ugts/main.py\", line 58, in <module>\n",
            "    main(args)\n",
            "  File \"ugts/main.py\", line 34, in main\n",
            "    acc,ece=command(args.exp_name, args=args,idx=i)\n",
            "  File \"/content/ugts/commands/train.py\", line 65, in train\n",
            "    learner = SupervisedLearning(outman, args, device)\n",
            "  File \"/content/ugts/models/supervised_learning.py\", line 103, in __init__\n",
            "    self.data=load_data(self.args.dataset,self.args.random_seed,self.args.attack,self.args.attack_eps)\n",
            "  File \"/content/ugts/models/Dataloader.py\", line 205, in load_data\n",
            "    return data.cuda()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch_geometric/data/data.py\", line 276, in cuda\n",
            "    return self.apply(lambda x: x.cuda(device, non_blocking=non_blocking),\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch_geometric/data/data.py\", line 245, in apply\n",
            "    store.apply(func, *args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py\", line 183, in apply\n",
            "    self[key] = recursive_apply(value, func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py\", line 657, in recursive_apply\n",
            "    return func(data)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch_geometric/data/data.py\", line 276, in <lambda>\n",
            "    return self.apply(lambda x: x.cuda(device, non_blocking=non_blocking),\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-1419aea9e6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nmode=score_only\\n#hidden=384\\ndataset=Cora\\nfor hidden in 256\\ndo\\n\\tfor depth in 2\\n\\tdo\\n\\t    for model in GAT\\n\\t    do\\n\\t        for S in 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\\n\\t        do\\n          #!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset WISCONSIN --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100\\n\\t        python ugts/main.py --command train  --num_layers $depth --dim_hidden 256 --dataset $dataset --heads 1  --train_mode $mode --linear_sparsity $S --exp_name test10 --epochs 400  --type_model $model  --weight_l1 0  --repeat_times 1 --sparse_decay --lr 0.01 --weight_decay 0\\n\\t        done\\n\\t    done\\n\\tdone\\ndone\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    135\u001b[0m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\nmode=score_only\n#hidden=384\ndataset=Cora\nfor hidden in 256\ndo\n\tfor depth in 2\n\tdo\n\t    for model in GAT\n\t    do\n\t        for S in 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\t        do\n          #!python UGTs-LoG/main.py --command train --lr 0.01 --num_layers 2 --dim_hidden 256 --dataset WISCONSIN --heads 1 --train_mode score_only --linear_sparsity 0.95 --exp_name test10 --epochs 400 --type_model GAT --weight_l1 0 --repeat_times 1 --sparse_decay --weight_decay 0.0 --random_seed 100\n\t        python ugts/main.py --command train  --num_layers $depth --dim_hidden 256 --dataset $dataset --heads 1  --train_mode $mode --linear_sparsity $S --exp_name test10 --epochs 400  --type_model $model  --weight_l1 0  --repeat_times 1 --sparse_decay --lr 0.01 --weight_decay 0\n\t        done\n\t    done\n\tdone\ndone\n' died with <Signals.SIGINT: 2>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9M6ma3NA0lyn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}